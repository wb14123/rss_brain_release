<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>4G Spaces</title>
		<description>我是徐宥 <br/><br/> <a href="https://www.ai.codes">创业中。</a>之前在 Fitbit (领导机器学习团队) 和 Google (广告和无人驾驶) 干活。华盛顿大学人工智能博士，南京大学数学学士。<br/><br/> 这个中文博客是我的思考记录，主要用来帮助我 debug/refactor 我的思想，但本人不对任何因为阅读造成的后果负责。<br/><br/> 一切文章皆为原创, 18岁以上的网友转载本博客文章请保留出处.  这里欢迎留言, 但没有智力活动迹象的留言将会被删除.</description>
		<link>http://blog.youxu.info</link>
		<atom:link href="http://blog.youxu.info/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>我的量化哲学和策略</title>
				<description>&lt;h4 id=&quot;section&quot;&gt;缘起&lt;/h4&gt;

&lt;p&gt;博客的老读者一看标题就会说，这是一篇和我博客文章风格迥异的文章。这篇的确是我所作。这是两年多的思考积累，写出来和大家分享。为了把我的思考轨迹讲清楚，先说一下我这几年的成长轨迹作为文章的起缘。&lt;/p&gt;

&lt;p&gt;上次写文章还是 2017 年从事 AI 方向创业的时候写的——一晃三年了。上次的创业公司不算很成功，最后把 IP (知识产权) 卖给了一家公司。之后我在 &lt;a href=&quot;https://www.reddit.com/&quot;&gt;Reddit&lt;/a&gt; 担任了两年的机器学习工程总监 (Director of Engineering)。从头建立了 Reddit 的机器学习研发团队，把 Reddit 的整个 Feed 系统算法化，个人化。帮公司在用户平均在线时间，广告投放点击率上实现了大于 50% 的质的飞跃。&lt;/p&gt;

&lt;p&gt;这几年在人工智能领域的工作和创业，使我对整个深度学习的方向有了深刻的认识。我认为， GPU 上运行的深度学习框架是一个通用的计算平台，作用不仅限于机器学习。于是，业余时间，我开始尝试用 TensorFlow 这样的深度学习框架去解决一些非机器学习领域的问题。其中的一个领域，就是量化金融。&lt;/p&gt;

&lt;p&gt;另一方面，三年里，我在职业和家庭人生这些方面都感到很满足很幸福。我有一个美好的家庭和一对健康成长的儿女。然而，这几年中，熟悉的朋友一个接一个肉身翻墙，国内发生的烦心事情越来越多。我还有父母和兄弟在国内，有时候不想关心国内信息也不可能。有天我&lt;a href=&quot;https://twitter.com/mathena/status/1196968225524707328&quot;&gt;在推特上说&lt;/a&gt;，“山河破碎，豺狼当道；麦秀粟离，沉郁悲呛”。一方面幸福平和，一方面沉郁悲呛，这样的心境于人于己都不健康。&lt;/p&gt;

&lt;p&gt;某天我突然想到古人的 “国家不幸诗家幸，赋到沧桑句便工”，突然想通了。当年遗山老人没有高级金融工具，只能悲愤而做岐阳三首，成为一代诗家。如今我们所在的时代给予了我们许多表达和应对“沉郁悲呛”的方法。我的策略是用当今的数学物理和金融工具，以求“量化沧桑尽微力”。这样微弱的改变，总比躲进小楼成一统好一些。是为缘起。&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;大变局时代&lt;/h4&gt;

&lt;p&gt;这是一个大变局的时代。技术本身更快地创造和摧毁资本价值。熊彼得提出的创造性破坏每天都在加速。   30 年前，S&amp;amp;P 500 公司在榜单里待的时间&lt;a href=&quot;https://www.innosight.com/insight/creative-destruction/&quot;&gt;平均是 33 年&lt;/a&gt;（出入榜很好地反映了价值和财富的创造和破坏），如今已经减少到 24 年，到 2027 年预测会继续减少到 12 年。 这方面例子比比皆是。如 &lt;a href=&quot;https://en.wikipedia.org/wiki/Charles_Schwab_Corporation&quot;&gt;Charles Schwab&lt;/a&gt; ，30 年前首先开创低价股票交易模式，破坏了当时的高价股票交易代理商，如今面对 &lt;a href=&quot;https://robinhood.com/&quot;&gt;Robinhood&lt;/a&gt; 这种免费交易对手的创造性破坏，也被迫推出免费股票交易。当年的创造性破坏者如今被新一代的公司创造性破坏。&lt;/p&gt;

&lt;p&gt;我相信技术是经济增长的内生动力。技术的进步是非连续的，这意味着对财富的创造和破坏也是非连续的。刚刚过世的哈佛管理学教授 &lt;a href=&quot;https://en.wikipedia.org/wiki/Clayton_Christensen&quot;&gt;Clayton Christensen&lt;/a&gt; 在&lt;a href=&quot;https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma&quot;&gt;「创新者困境」&lt;/a&gt; 里描述了这种非连续性：行业领先的公司似乎忽然之间就被小公司超越。上面我们说到 S&amp;amp;P 500 榜单公司的平均寿命越来越短，其实是技术的破坏创造力越来越大的体验。&lt;/p&gt;

&lt;p&gt;大变局也意味着大泡沫，一些公司看上去代表了新经济新技术，实际上内里全是泡沫，只是故事讲得好。所幸的是，物理学已经给我们指点了一套识别泡沫的方法。&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;大变局时代的物理金融方法&lt;/h4&gt;

&lt;p&gt;几十年前，我们还可以把技术当成外部变量来处理量化模型。随着技术对财富的加速创造和破坏，我们很难将技术排除在模型之外还能准确地计算资产价格。把技术纳入财富的创造和破坏模型，即抛弃传统的微观和宏观经济学的框架，拥抱复杂系统科学（物理学），拥抱&lt;a href=&quot;https://ergodicityeconomics.com/&quot;&gt;非遍历经济学&lt;/a&gt;，拥抱内生经济模型。&lt;/p&gt;

&lt;p&gt;用复杂系统（相变）的眼光来看金融市场——随着整个市场的自动化程度越来越高，相变也越来越频繁。这样频繁的相变意味着两点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;第一，我们需要用复杂系统的数学物理方法来量化金融市场，而不是传统的随机游走理论。如「黑天鹅」的作者 Nassim Nicholas Taleb，一直在强调不要用随机游走的方法来量化市场。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第二，传统的价值投资（以巴菲特为代表）可投资的领域在变小。巴菲特的投资哲学着力寻找那些高质量，未来一二十年有稳定增长的公司。但随着破坏性创造越来越频繁，这些股票越来越难找。事实也是如此，Berkshire Hathaway 如今手握大笔现金（总计 1280 亿美元），近四年来都没有出手任何大的投资标的，而是回购自己的股票支撑价值。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总的来说，新的内生经济增长方式决定了判断金融资产价值的方式要超越简单的未来现金流折现，因为未来现金流折现蕴含着连续性假设，而如今的未来是一个不连续的方程，尤其是在技术变革，动力转换和泡沫成长破碎的时候。这些非连续的事件正是可以让收益超过市场平均的机遇。&lt;/p&gt;

&lt;h4 id=&quot;section-3&quot;&gt;模型的业绩&lt;/h4&gt;

&lt;p&gt;通过去年一年的实际操作，结合上面说的物理方法，我认为我找到了一套行之有效的量化哲学和策略。我把这个方法很粗暴地命名为 &lt;strong&gt;“大跃进” / Great LEAPS&lt;/strong&gt;。我自己管理的对冲基金也就暂且叫做&lt;strong&gt;大跃进基金&lt;/strong&gt;。 命名后面的逻辑后面我再解释。&lt;/p&gt;

&lt;p&gt;在阐述具体方法之前我讲一下我去年的成果。去年一年我总资产的年化收益约为 45%。 今年第一个月收益接近 14%。 所有收益均采用量化模型，而非基本面分析，技术分析等等。交易则由我手动执行。因为不是高频交易，手动执行和自动执行差别不大。&lt;/p&gt;

&lt;p&gt;去年我最大部分收益来自于做空 NIO （蔚来汽车）。模型从它的股价大跃进里发现泡沫。我于 2019 年 1 月 19 日购买 N 手 2019 年 8 月 16 日到期的 PUT 期权，行权价格为 $14，购买价格为 $7.80/share。 至 2019 年 8 月 16 日，NIO 股价跌至 $2.96, 我以 $11.04/share 卖出，收益率为 146%。 其他操作收益不等，不占主要。&lt;/p&gt;

&lt;p&gt;今年（2020年）第一个月我最大的收益来自 LK (瑞幸咖啡)。同样使用量化模型找到泡沫。我于 2020 年 1 月 10 日购买 N 手 2021 年 1 月 15 日到期的 PUT 期权，行权价格为 $35.00。购买价格为 $9.00。至今 LK 股价已跌落至 $31.36，而该期权价格升至 $13.40，如果今日卖出收益率为 148%。事实上，我基于基本面判断 LK 的真实股价为 $0。但这和模型无关，我在等待模型给出的另一个下跌窗口出手。&lt;/p&gt;

&lt;p&gt;以上两例，尽管都和中概有关，但模型本身没有特别的给中概股权重。做空泡沫需要一定的勇气和耐心。比如做空蔚来的时候，著名做空机构香橼发布了一份做多的报告，我的总基金纸面上的损失达到了60%。但模型的威力是明显的，蔚来之后股价一路下跌。&lt;/p&gt;

&lt;p&gt;随着中国经济的失速，这样的机会还有很多。在中国，增速的技术遇到了制度和人口结构变化，呈现出了独特的破坏式创造的风格。许多人主张做空中国（人民币，ETF，或者一些夕阳产业）。我的信念是这种笼统做空方式收益风险比过低。做空中国本身已经是一个有效市场，况且体制本身的行为很难在量化模型中刻画出来。&lt;/p&gt;

&lt;h4 id=&quot;section-4&quot;&gt;用深度学习的牛刀来屠量化金融的龙&lt;/h4&gt;

&lt;p&gt;上面我提到，大变局伴随的是物理的相变过程。然而，从短期趋势来说，发生的时间不可预测，也不可计算。这几天，许多做空 Tesla 的人都被其股价上扬震惊了。事实上，短期市场永远是一个难以预测的怪兽。短期要切准时间太难了。&lt;/p&gt;

&lt;p&gt;然而，从中长期来看，我们有较好的预测相变的办法。比如， &lt;a href=&quot;https://en.wikipedia.org/wiki/Didier_Sornette#The_JLS_and_LPPLS_models&quot;&gt;LPPLS&lt;/a&gt; 模型可以预测泡沫的破碎。然而，现有的模型优化手段非常粗糙（遗传算法），很难稳定收敛到一个可信的值。在这方面，华尔街和物理学家还没能普及更好的模型优化算法。其实更好的模型优化算法已经出现，即现有的深度学习框架。这里，并不是要用深度学习/神经网络本身来做量化金融，而是用深度学习领域的技术工具。这是一个非常独特的机遇，因为：&lt;/p&gt;

&lt;p&gt;一方面传统的华尔街/量化公司已有一套完善的量化工具，但这些工具的模型表达和优化能力远不及 TensorFlow。另一方面，懂得 TensorFlow 这些工具的人目前都忙于做人工智能，还很少有人来捕捉量化金融的机会。TensorFlow 框架在量化金融上可以做许多事情。我觉得以后量化金融会逐步转移到这种全面的计算框架上来。我不怕写出来和大家分享这个“秘密”，因为目前能够把两者都玩转起来的能太少，我宁愿这样的人多一些才好。 同时，我认为未来几年，这个“秘密”武器有一定的先发优势，可以在一些模型上比它人获得更加好的结果和汇报。&lt;/p&gt;

&lt;p&gt;对我来说，TensorFlow 和 GPU 可以用来预测和捕捉复杂系统的相变时刻。这样的预测必然是一种近似，而非科学预测。所以，问题是，有了相变（比如泡沫大概什么时候破碎）的信息，如何从金融市场中套利？知道信息本身只是10%的工作，用正确的工具来套利是 90% 的工作。&lt;/p&gt;

&lt;p&gt;通过这一年的实践我找到了一个适合的金融工具，这个工具的名字叫 LEAPS，即长期期权。而在实践中，这是一个它山之石，长权短用，寻求高额回报。&lt;/p&gt;

&lt;h4 id=&quot;leaps-&quot;&gt;LEAPS 工具&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cboe.com/education/getting-started/quick-facts/leaps&quot;&gt;LEAPS&lt;/a&gt; 是一种特殊的期权，这种期权的过期日期往往在一年开外。因为美式期权的特点，意味着你有很长的时间来等待收益。当然，世界上没有便宜的午餐，长时间意味着更高的期权价格，也意味着小的 &lt;a href=&quot;https://www.investopedia.com/terms/t/theta.asp&quot;&gt;Theta&lt;/a&gt; 值。&lt;/p&gt;

&lt;p&gt;做空并不是一件复杂的事情。然而，价格下行或许能立即发生，或许还要等几个月，或许半年内都不会发生。这正是许多做短期看空期权的人需要冒的风险，也是许多人倾家荡产的原因。在我看来，用短期期权去赌股价的上下，除非有额外的信息，否则真的是赌博。&lt;/p&gt;

&lt;p&gt;在随机游走的假设下，LEAPS 本身也是公平的赌博。然而，当 LEAPS 和物理金融方法以及 TensorFlow 模型结合在一起，LEAPS 就有了一个新的维度： 用随机游走的量化模型计算出的期权价格 (现有的 LEAPS 定价策略)，与用物理方法计算出的模型相比，在相变前期，后者能更加准确地刻画相变，更加符合金融市场的实际情况。方法本身没有好坏，差别在假设上。我相信，能够导出股价变化遵循 Power Law 分布的物理量化模型，比不能够导出 Power Law 的模型更加准确地捕捉相变。&lt;/p&gt;

&lt;p&gt;一般专业交易者把 LEAPS 当成长期风险对冲工具。我的用法可以算是“直板横打”。我将 LEAPS 当成低风险的短期收益工具。以看空期权为例，在股价不变前提下，通过不断计算 LEAPS 的剩余价值，我可以控制时间流逝带来的折损。如果泡沫不破碎，则在其时间价值迅速贬值之前出售。如果等到泡沫破碎，则出售换取超额收益。当然，如果股价上涨，看空期权必然下跌，所幸的是，因为没有要紧的时间压力，你有选择等待的空间。&lt;/p&gt;

&lt;p&gt;在这种策略下，收益不是从每日交易中得到，而是在等待中出现。这里的秘密是： Theta 函数随时间的变化是非线性的。在股价不变的前提下，LEAPS 前期的贬值极低，刨去市场无风险收益率，在前六个月几乎可以算是免费持有。&lt;/p&gt;

&lt;p&gt;这里细节上还有一些有意思的东西，比如，依赖于 &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo&quot;&gt;Hamiltonian Monte Carlo&lt;/a&gt;  方法，我们可以用 MCMC 和一套新的假设给 LEAPS 期权定价。一些原本不能做到的套利行为也可以在 TensorFlow + GPU 的帮助下完成。&lt;/p&gt;

&lt;h4 id=&quot;section-5&quot;&gt;结语&lt;/h4&gt;

&lt;p&gt;说到这里，我把这套对冲策略和基金命名为 &lt;strong&gt;Great LEAPS/大跃进&lt;/strong&gt; 也就明白了。我的策略就是用量化的方法寻找那些看上去好像股价大跃进，其实内里土法炼钢的股票。找到后，用 LEAPS 策略套利。这套工具链和逻辑链能够成立，依赖于时代的机遇和泡沫，依赖于众多物理学家，数学家和机器学习工程师所构建的基础。&lt;/p&gt;

&lt;p&gt;限于篇幅许多理论和实践没有一一展开。我一直相信，如果勤于思考的话，钱会来敲门。基于此，我宁愿写出来和人分享我的思考，希望更多的人知道模型和量化的力量。&lt;/p&gt;
</description>
				<pubDate>Tue, 04 Feb 2020 12:33:01 +0000</pubDate>
				<link>http://blog.youxu.info/2020/02/04/my-leaps-strategy/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2020/02/04/my-leaps-strategy/</guid>
			</item>
		
			<item>
				<title>AI 创业的一点思考</title>
				<description>&lt;p&gt;2016 年 8 月，我从 Fitbit 离职创业，做一个&lt;a href=&quot;https://www.ai.codes&quot;&gt;用 AI 帮助程序员更好的写代码的公司&lt;/a&gt;。在过去的四个月里，通过无数的模型，产品和数据的迭代，加之和用户交谈，以及观察其他的创业者，我积累了一些想法，写下来抛砖引玉。&lt;/p&gt;

&lt;h4 id=&quot;ai--ai--ai&quot;&gt;此 AI, 是名 AI, 非 AI.&lt;/h4&gt;

&lt;p&gt;这一波的 “AI” 创业热潮，准确的说应该是“深度学习算法”创业潮。人工智能本身是一个涵盖极大的领域，除了学习和表示（深度学习的主要领域）之外，还有推理，规划等等其他大量分支。普通人理解的人工智能，大多数都是“强人工智能”的范畴（一个可以完全代替人的智慧的机器）。而大量的创业公司都纷纷采用 .ai 做为域名后缀，实质上只是在“深度学习”这个子领域，解决一些特定的，以前只能靠人的智慧才能解决的问题。&lt;/p&gt;

&lt;p&gt;就和 .com 时代一样，域名后缀的符号意义远大于实际意义。媒体，投资人和创业者都默默接受了 .ai 这个集体幻觉。总的来说，目前 AI 公司的井喷，是深度学习这项技术完成其技术扩散 (&lt;a href=&quot;https://en.wikipedia.org/wiki/Diffusion_of_innovations&quot;&gt;diffusion of innovations&lt;/a&gt;) 的体现。在 Google, Facebook 等技术领先企业的示范和大笔收购下，风险投资大量向 AI 倾斜。许多掌握机器学习和深度学习的人才，认识到深度学习可以用来解决一个具体的问题，也流动到创业公司开始创业。因为 AI 入门门槛很高，目前还是很容易从创业者的教育和工作经历来甄选到底一个公司做的是不是深度学习，还是挂羊头卖狗肉的。&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;深度学习的确“创造”了许多创业公司可以挑战的新问题&lt;/h4&gt;

&lt;p&gt;有许多了解和从事机器学习的人，并不觉得这一波的“深度学习”技术有多神奇。这是可以理解的，因为深度学习的主要技术 30 年前都齐备了，只是最近被某种魔法召唤出来。在我看，这一波的 AI 创业潮，不是泡沫，是对多年没有在工业界铺开的机器学习技术的复仇。过去的十多年中，我们经历了互联网时代，社交网络时代和移动时代。有了众多的站点，社交网络和应用。机器学习和云计算解决了许多问题，如搜索引擎，大数据处理，但仍有许多问题，如图像，视频，语音，自然语言的处理，都是传统的机器学习方法没有能很好解决的。深度学习的出现，使得解决这些问题成为了可能。&lt;/p&gt;

&lt;p&gt;解决问题的工具进化后，以前大家没觉得是问题的（主要是解决不了），现在变成了问题。一个最简单的例子是自动驾驶。我在 Google 自动驾驶部门工作的时候，视觉系统还是用的传统的物体识别方法，有许多规则和边界情况要额外处理。汽车一方面需要额外引入其他传感器的数据做判断，另一方面需要不断分解自动驾驶问题为行人识别，自行车识别，信号识别等子问题。所有的子问题加起来，工程复杂度太高，创业公司是很难组建出一个能解决这个问题的团队的，而且所谓的“解决”，也不能达到商用的地步。拜深度学习所赐，如今从视觉信号，模仿人类驾驶行为，就可以做到高质量的巡航控制。这时候，自动驾驶问题就变成了一个创业公司可以挑战的问题。2016 年这个领域新闻一个接一个。Cruise 今年被 GM 收购，Comma.ai 获得了 A16Z 的投资等等，都是自动驾驶领域创业公司成功的例子。在许多的细分行业，这样被深度学习“创造”的新问题不胜枚举。然而，&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;想要成功，单解决一两个问题是不够的&lt;/h4&gt;

&lt;p&gt;深度学习是一项技术。这个黑科技可以作出更加准确的机器学习模型，但更好的模型仍然要通过产品落地。特别是创业公司，在没有相关平台支撑的条件下，解决一两个问题很难给用户带来实际价值。在技术史上，没有一家技术公司是依靠一个领先的机器学习模型就成功的。即便 Google 这个以 PageRank 为核心算法起家的技术公司，也是通过将技术包装成一个优秀的搜索引擎而落地的 （当年的 Yahoo! 甚至还看不上这个技术）。&lt;/p&gt;

&lt;p&gt;这里面的原因，可以分成 To B 和 To C 两个方向来说。&lt;/p&gt;

&lt;p&gt;目前深度学习所解决的问题，大部分都在图像，人脸，视频，文本等领域——因为深度模型大部分都是为解决这些问题而设计的。靠一两个深度学习专家，创业公司完全有实力去挑战如图像分类，语音识别等通用问题。然而，解决通用问题的门槛只有一个：只要跳过了这个门槛，前方就很难再建护城河了。对用户有价值的通用问题，特别是 To B 的通用问题，一定是对巨头有价值的。2016 年，Google 和 Microsoft 都发布了图像，语音识别等通用 API。一个明确的趋势是，云服务商正在把这些基于 AI 的服务做成平台的一部分。在同样的图像分类服务面前，巨头的服务一定比创业公司要廉价。如果没有巨大的先发优势。创业公司在这个方向很难抵抗云服务巨头的侵蚀。此外，把针对通用问题的机器学习模型，浅包装成一个 API，的确容易切入市场，但也容易被巨头和其他创业公司碾压。现在市场上有许多浅包装深度模型的公司，提供如“鉴定黄色图片”等服务。在我看来这些服务的可替代性太强，大家技术差别也不大，最终能胜出的，只会是一两家有先天优势的公司（比如云服务巨头，或者第一个进入市场的公司）。To B 的 AI 创业公司的挑战不在技术上，而在产品创新上。怎么制造差异化服务，让这个服务无可替代——这就看各家公司的想象力了。&lt;/p&gt;

&lt;p&gt;在 To C 方向，2016 年许多创业公司都做了很多尝试。今年很火的 &lt;a href=&quot;http://prisma-ai.com/&quot;&gt;Prisma&lt;/a&gt;, 就是将风格迁徙神经网络运用到用户照片上，将照片转换成各种艺术家风格。Prisma 可以算是提供了一个杀手级的特性了。即便这样，创业公司想靠一个特性和巨头竞争也是不可能的。Prisma 不可能靠这一个特性取代 Instagram，即使 Instagram 没有这些人工智能的滤镜。原因很简单，IG 控制了移动时代的大量的用户群，因此 Prisma 制作的照片最终还要通过 Instagram 才能传播出去。To C 方向的先发优势是不可估量的：一旦用户形成使用习惯和网络效应，再好的 AI 产品也很难转化现有用户。其实这个问题困扰所有的公司。比如 Google 今年连续在 Gmail, Google Docs 里做了许多 AI 创新，还发布了 Allo 这个全新聊天工具。可是，大量用户依然用着 Office 和 Facebook Messenger。&lt;/p&gt;

&lt;p&gt;说了这么多，好像很悲观。To B 和 To C 都困难重重的样子。其实机会还是非常多的，只是没有“AI = 创业机会”这样一个自动成立的等式而已。&lt;/p&gt;

&lt;h4 id=&quot;ai-&quot;&gt;AI 创业公司的优势&lt;/h4&gt;

&lt;p&gt;先说什么不是优势，或者护城河。其一，如果创业是凭借着一个“独特的算法或模型”，这个切入点是靠不住的。AI 创业已经过了 2014－2015 巨头为了收人而收购公司的阶段。目前投入到创业浪潮中的，都不大可能是当时巨头收漏了的。在这种大环境下，没有任何一项技术是别人不知道的，或者非常领先所有竞争对手的。目前宣称有独特模型和算法的，是把赌注押在一个特定的方法上，而和全世界的所有研究者竞争。目前来说这注定是无效的——谁也不知道明天 DeepMind 会公开什么黑科技，一下子超越了你的独特模型。或许在这个赛道上再走几年，有些公司的确能够领先其他。目前大家都在同样的起跑线上，模型或者算法的领先可以忽略不计。&lt;/p&gt;

&lt;p&gt;其他，“把标准问题做到极致”既不是护城河，也不是竞争优势。如果回到 2012-2014 年，哪个创业公司能够用深度学习在 ImageNet 上刷出第一，肯定是立即像 &lt;a href=&quot;https://techcrunch.com/2013/06/12/how-googles-acquisition-of-dnnresearch-allowed-it-to-build-its-impressive-google-photo-search-in-6-months/&quot;&gt;DNNResearch&lt;/a&gt; 那样被巨头揽走。其中一个原因，是用深度学习的人太少了。现如今，世界上攻克标准问题的团队，百分之百都是用深度模型。当全世界的学术团队都来刷榜的时候，创业公司耗散精力去刷榜是不经济的。而且，刷榜要求的，许多时候是特定的工程技巧，未必能用到产品中。一个典型的例子是当年 Netflix 竞赛的第一名，它们的模型过于复杂，没法产品化，Netflix &lt;a href=&quot;http://arstechnica.com/gadgets/2012/04/netflix-never-used-its-1-million-algorithm-due-to-engineering-costs/&quot;&gt;最终也没有采用&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;在我看来，AI 创业，还是要落实在&lt;strong&gt;深入解决一个非标准（不能拿标准的深度学习模型一套就能用）的问题上&lt;/strong&gt;。只有在非标准的问题上，切实的了解用户需求才变成可能。标准的问题，如图像识别，自动驾驶，可以说，最终产品的亮点大家都差不多，因此人工智能也就不自动成为一个亮点。在非标准的问题上深耕，无形中就构建了两个护城河：1，竞争对手需要花时间了解这个问题之后才能提出解决方案和产品；2，你比竞争对手先收集许多解决这个领域特定问题的数据，因此在同一时间节点上，你的模型永远领先对手几个月。这就像微软的搜索引擎或许使用的模型很先进，但因为没有足够的数据因此质量永远落后 Google 几个月一样。&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;最后的话&lt;/h4&gt;

&lt;p&gt;解决非标准的问题，需要的就不仅仅是 AI 人才。对特定行业的了解，痛点的把握，对用户的理解等等，往往比 AI 更加重要。在这一点上，AI 创业者可能会死磕模型和数据，或者只想着找最顶尖的 AI 研究者，而忘记了真正对用户有价值的东西。模型只是整个产品世界里很小的一部分。AI 创业公司不代表 AI 是唯一重要的事情，这一点算是我前面四个月学到的一点经验。&lt;/p&gt;
</description>
				<pubDate>Wed, 04 Jan 2017 12:33:01 +0000</pubDate>
				<link>http://blog.youxu.info/2017/01/04/thinking-in-ai-startups/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2017/01/04/thinking-in-ai-startups/</guid>
			</item>
		
			<item>
				<title>深度学习 Meetup 总结</title>
				<description>&lt;p&gt;前几天参加湾区同学技术沙龙组织的一次专门面向深度学习的 meetup。做了一些笔记如下。&lt;/p&gt;

&lt;p&gt;这次活动的嘉宾包括 Google 的 Yonghui Wu (&lt;a href=&quot;https://arxiv.org/abs/1609.08144&quot;&gt;GNTM 系统&lt;/a&gt;一作)，Kai Chen (Google Brain 早期成员，经典 &lt;a href=&quot;https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf&quot;&gt;Word2Vec 论文&lt;/a&gt;共同作者），Yuan Li (Google Research TLM)，以及 Zhenghua Yu (VP, Bocom).&lt;/p&gt;

&lt;p&gt;因为活动以问答形式展开，我也以问答形式记录。&lt;/p&gt;

&lt;h4 id=&quot;q1-&quot;&gt;Q1: 这几年深度学习方向有哪些很重要的突破?&lt;/h4&gt;

&lt;p&gt;Yuan 首先谈到了视觉领域的一些突破。实际上我们都知道引爆这轮深度学习热潮的，就是 2012 年把第二名甩出十几个百分点(以分类精度测量)的 &lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-&quot;&gt;AlexNet&lt;/a&gt;. 在 AlexNet 之后，视觉领域比较有代表性的几个网络是 Oxford VGG, &lt;a href=&quot;https://arxiv.org/abs/1409.4842&quot;&gt;GoogLeNet (Inception Module)&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;ResNet&lt;/a&gt; 和最近的 &lt;a href=&quot;https://arxiv.org/abs/1602.07261&quot;&gt;InceptionResNet&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Yonghui 和 Kai 谈到了自然语言处理里的一些突破。大家熟知的 Word2Vec 以及后续的一些工作如 &lt;a href=&quot;http://nlp.stanford.edu/projects/glove/&quot;&gt;GloVe&lt;/a&gt;. &lt;a href=&quot;https://arxiv.org/abs/1409.3215&quot;&gt;Seq2seq&lt;/a&gt; 做为一个通用框架已经在自然语言处理领域四处开花，包括翻译，标注等一系列的自然语言处理任务都可以直接上 Seq2seq.&lt;/p&gt;

&lt;h4 id=&quot;q2--ai-&quot;&gt;Q2: 还有哪些有趣的 AI 问题值得探究？&lt;/h4&gt;

&lt;p&gt;众多嘉宾都纷纷表示尽管这个领域现在 hype 很多，总的来说这个领域才刚刚开始，要研究的问题很多。在理论层面就有许多亟待解决的问题。在具体的应用层面，尽管翻译和语音识别等等问题看上去都已经解决，但开放式的对话问题仍然没有解决。从深入生活的应用来看，可以和人交流和帮助完成家居任务的机器人，可以做为医疗助手的人工智能，可以智能控制交通的调度系统等等都是很有趣的问题。Yuan 还提到了目前在视觉方向搭更大更深的网络已经不是潮流了，更多的分类标签，更加难的基准，如 &lt;a href=&quot;http://mscoco.org/&quot;&gt;MsCoCo&lt;/a&gt;，是现在众多研究者的发力方向。&lt;/p&gt;

&lt;h4 id=&quot;q3-&quot;&gt;Q3: 深度学习取得的进展更多是科学还是工程上的？&lt;/h4&gt;

&lt;p&gt;在这个问题上，Yonghui 非常具体的谈了他实现 GNMT 的经历。NMT 的构想，最早可以追溯到 Yoshua Bengio 的 Word Embedding 开山之作，&lt;a href=&quot;http://www.jmlr.org/papers/v3/bengio03a.html&quot;&gt;A Neural Probabilistic Language Model&lt;/a&gt;。 之后，词嵌入技术，Seq2seq 框架，以及 Attention Model 等等一起，奠定了 NMT 的理论基础。然而，NMT 最早在基准数据上，效果是低于 Google Translate 所采用的 phrase-based translation 系统的。即便这样，NMT 代表了一种新的范式，可以用大量的数据来训练模型，提高翻译质量。&lt;/p&gt;

&lt;p&gt;按照 Yonghui 的叙述，GNMT 系统是工程学的胜利：他们从一个研究性的系统开始，引入了深度学习工程上熟知的一些技术，比如 &lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;Attention Mechanism&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1604.00788&quot;&gt;word piece model&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;residual links&lt;/a&gt;。最终，将模型成功的放到了 Tensor Processing Unit 上而不显著损失模型精度。所有的这些，都应该是工程学的胜利。至于科学上的贡献，就是毫无疑问地证明了 NMT works.&lt;/p&gt;

&lt;h4 id=&quot;q4-&quot;&gt;Q4: 中美两国在深度学习的开展上有什么不同？&lt;/h4&gt;

&lt;p&gt;嘉宾都一致认为，深度学习方向上奠基性的工作还是在北美完成的。中国的深度学习开展还偏于应用层面。不过中国的优势是，真实应用的数据集比北美大而且获取成本低。或许中国在深度学习方向上可以出现一批在北美不会出现的应用。&lt;/p&gt;

&lt;h4 id=&quot;q5-&quot;&gt;Q5: 在深度学习工作上遇到过哪些坑？&lt;/h4&gt;

&lt;p&gt;Kai Chen 博士在这一点上举了一些具体的例子。比如，在 debug 模型时，将数据低维化，可视化，比如用 t-SNE 将数据映射到二维。另外，必要时要打开神经网络的黑盒子，让模型可解释。不可解释的模型往往也很难调试。Yu 博士则提到要规划数据采集。因为数据采集是一个费时费力的事情，要在一开始就规划好，控制好数据的噪音，并且争取一次收集足够的数据，因为二次采集时可能一些指标已经和第一次不一样。Yonghui 也提到了翻译模型里的一些失败情形，在这种情况下要知道模型的大致应用范围，使得模型在合适的工作条件下发挥作用。&lt;/p&gt;

&lt;h4 id=&quot;q6-&quot;&gt;Q6: 对转行做深度学习的建议&lt;/h4&gt;

&lt;p&gt;几位嘉宾都表示他们原本也不是从事深度学习方向工作的，都是最近几年进入这个领域的。因为深度学习领域有众多的开源框架，并且还在快速的发展中，几位嘉宾都表示现在进入对于初学者是最有利的，因为即使是深度学习的老手，也要天天跟踪最新的研究成果，以保持知识的及时更新。&lt;/p&gt;

&lt;p&gt;Yuan 还举了一个非常经典的例子（其实是两个例子）。一个是 Christian Szegedy, 原本是数学家，从事逻辑电路的设计，后来转行从事深度学习，凭借在数学上的深厚功底，成为 GoogleLeNet 架构设计者。另一个例子是 &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/&quot;&gt;Oxford VGG&lt;/a&gt; 研究组了。 2012 年他们的 Fisher Vector 方法&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2012/results.html&quot;&gt;被 AlexNet 打败&lt;/a&gt;，然而 2014 年他们推倒之前的一切工作，从头开始从事卷积网络研究，并一举赢的当年 ImageNet &lt;a href=&quot;http://image-net.org/challenges/LSVRC/2014/results&quot;&gt;两个分项的冠军&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;以上是我简要的笔记。通过参加这次以及其他的一些 meetup，我总的感觉是 Google 等大鳄在深度学习方面的人才和资源积累远在其他公司之前，原因和当年大数据时代 Google 领先行业一样：Google 要解决的问题和拥有的数据远比其他小公司多。不过话说回来，这轮 AI 浪潮带来的新问题很多，许多是 Google 不愿意做或者不屑于做的。希望这一波的 AI 浪潮能够让深度学习技术更加民主化，更多的 AI 技术能够被整个行业采用。&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section&quot;&gt;广告&lt;/h4&gt;

&lt;p&gt;最后毫不要脸地插一个广告: 我的创业公司, &lt;a href=&quot;https://www.ai.codes&quot;&gt;AI.codes&lt;/a&gt;, 致力于将人工智能技术应用于分析和预测计算机代码，目前发布了一个 &lt;a href=&quot;https://plugins.jetbrains.com/plugin/9203?pr=idea&quot;&gt;IntelliJ 插件试用版&lt;/a&gt;，仅支持 Java。同时，欢迎有一定人工智能或编译器知识基础的同学加盟。目前公司处于起步阶段，股权等各项待遇在硅谷创业公司中绝对属优。不在湾区但对这个项目感兴趣的朋友也可以直接和我联系，我的邮件地址是 exu@ai.codes.&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Sun, 23 Oct 2016 12:33:01 +0000</pubDate>
				<link>http://blog.youxu.info/2016/10/23/tech-meetup/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2016/10/23/tech-meetup/</guid>
			</item>
		
			<item>
				<title>技术管理猪鸡-1 开篇</title>
				<description>&lt;h3 id=&quot;section&quot;&gt;高效的秘密&lt;/h3&gt;

&lt;p&gt;我正式走上职业生涯是 2011 年秋天，完成了博士学业，踌躇满志地加入了 Google。当时，我的理想是做 Google 里生产率最高的软件工程师。为此，我列了一个高效工程师名单，看他们每天提交的代码是些什么，以从中学习高效的工作方法。这个名单里有 Jeff Dean, Sanjay Ghemawat, Rob Pike，还有一些 Google 内 7 级以上的工程师。因为 Google 内部源代码提交全部公开，我可以看到他们每天的工作内容。&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  很快，从读这些代码中我认识到了一点：人每天只有八个小时工作时间，谁都一样。其中能高效工作的时间绝对不超过4个小时。这些工程师编写的代码行数绝对不算多，但从事的项目影响大。比如 Pike，大部分时间花在了审查其他成员的 Go 代码上。而一个刚入行的 Golang 工程师，每天的任务就是写作 Go 的标准库，今天写 http 明天写 sort，写的比 Pike 多很多。考核时，高级工程师因为带领着高效团队，每季度 OKRs 上都有诸多亮点；而刚入行的工程师，只能报告一些比较琐碎的成就。
&lt;/p&gt;

&lt;p&gt;这个观察近乎于常识，然而对于当时的我来说是一个顿悟：做出 MapReduce 框架的和写琐碎 MapReduce 程序的工程师之间的差距并不是他们的工具和编程效率，也往往不是教育背景或者经验，而是他们各自的杠杆：所带领的团队。&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  问题是，没有人会给你这个杠杆。于是，我开始观察别人的杠杆是怎么搭建的。
&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;运用常识&lt;/h3&gt;

&lt;p&gt;Google 的芝加哥 office 有两个技术领导：Brian Fitzpatrick 和 Ben Collins-Sussman。他们合写了一本书，叫做 Team Geek。近水楼台，我就拿了一本过来看。或许对于 Google 之外的人来说，这本书讲了许多有价值的东西，对于 Google 员工来说，基本上书里面说的就是公司每天实践的，因此读来觉得都是常识。这让我突然领悟到，其实所谓的团队工作，或许说白了就是正确地运用这些常识。&lt;/p&gt;

&lt;p&gt;在实践中运用常识远比想像中的难。有一次在搏击课上，师傅让我和某个拿过法式拳击世界冠军的师兄对练。他手腿都很长，出拳又快，根本拿不到破绽。为了不被首轮打倒，我不得不满场跑着闪躲。躲着跑过师傅的时候，他就说了一句：“你只管出拳，不出拳永远赢不了点数”。其实这是每个学搏击的人都知道的常识，却因为一时的恐惧彻底忘了。做技术领导时也是一样，许多我们知道的常识性的东西，一旦遇到复杂情况，我们往往依赖于旧习惯和情绪反应，忘了要解决的问题，忘了运用常识做出正确的判断。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;逐渐习得的管理技能&lt;/h3&gt;

&lt;p&gt;常识是可以习得的，因为每个人都有包容常识的心性。问题是，所谓常识，是名常识，实非常识。根本没有一本叫做“技术管理常识”的书，读完就事理无碍了。在领悟到技术管理其实是运用基本常识之前，我买了一大堆的关于技术管理的书，幻想能够博闻强记速成。想明白“习得”这一点，让我轻松了好多：这不是入学考试，慢慢积累最省时省事。就像练习武术一样，最强的斗士绝不是看书最多或者理论最强的，而是训练时间最长的。&lt;/p&gt;

&lt;p&gt;我曾经也醉心于一些管理方法。比如说，&lt;a href=&quot;https://en.wikipedia.org/wiki/Kanban&quot;&gt;Kanban&lt;/a&gt; 管理法是照搬了丰田在七十年代的高效率生产模式而提出的。06年第一次读这个管理方法的时候崇拜无比。到了2009年，丰田汽车在世界范围内发生了多起质量问题召回的事情，使我重新审视这个问题：任何管理方法都是为了解决某些类问题而催生的。问题变了，不管以前多么神奇的管理方法都会变得一地鸡毛，因为管理方法不能脱离要解决的问题。&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  也就是这个时候，我重温了温伯格的《&lt;a href=&quot;http://book.douban.com/subject/4187478/&quot;&gt;技术领导之路&lt;/a&gt;》。这本书对于我来说最有价值的一点，是让我体会到尽管管理方法成千上万，归根到底需要一些“元方法”去支配。比如，书中提到了一个大家都明白的元方法：写日记。技术领导者每天写日记，记下每天的活动，反思一些事情。尽管写日记并不能直接解决技术管理上的难题，却打开了反思之门，也把许多事情前因后果连接起来。比如，通过在日记里反思一些会议的效率，我开始有意识地反思高效率的会议和低效率的会议的差别，并主导一些会议的日程。显然，真正的问题不是要不要设定议事日程（元方法），而是学会怎样设定一个特定会议的议事日程（解决问题的方法）。而后者，只能通过设定议事日程学到。
&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;管理模型&lt;/h3&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  我是一个理科生。理科生理解世界的第一工具是模型。世界过于复杂，人脑计算能力有限，只能付诸模型抽象简化。技术管理作为技术（工程学）和管理（自然科学）的横切点，自然免不了各种各样的模型。技术管理的模型本身多种多样。人月神话模型，人件模型，丰田模型，温伯格模型，Agile 模型，Lean 模型等等不可枚举。对于一个技术管理人员来说，幸运的是，所有的模型都是错的，所以即使不知道这些模型，也未必遗漏了什么重要的。不幸的是，有些模型的确比较有用，所以知道一些还是有好处的。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  正因为此，我开始收集一些工作中积累的管理模型 (Pattern)，像 GoF 的 Design Pattern 一样，列出要解决的问题，模型，和自己的实现。我收集了不少细碎的模型。有时候觉得过于细碎，不足为外人道也；有时候又觉得好像还是有些用处的。
&lt;/p&gt;

&lt;p&gt;就这样，在不断的写作懒惰症中过了三四年。直到最近，说来也巧，在检查一个 bug 的时候发现有某用户调用 Fitbit 的食物记录 API 中试图存下 “🐷🐔”，这提醒了我那个著名的 &lt;a href=&quot;http://en.wikipedia.org/wiki/The_Chicken_and_the_Pig&quot;&gt;The Chicken and the Pig&lt;/a&gt; 笑话，以及我的好友 Tinyfool 一直开玩笑说我写的“编程猪和鸡番外篇”系列，促发了我写作“技术管理猪鸡”的想法。这一篇，算是一个很不正式的开头。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;&lt;em&gt;PS: 好友余晟翻译的温伯格的《&lt;a href=&quot;http://book.douban.com/subject/4187478/&quot;&gt;技术领导之路&lt;/a&gt;》一书将要再版。这本书里包含了许多技术管理的“元方法”，以及作者提出的 MOI 管理模型（不幸的是这个模型比较有用）。推荐对技术管理（不仅限 IT 行业）有兴趣的读者购买。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;
</description>
				<pubDate>Sun, 17 May 2015 12:33:01 +0000</pubDate>
				<link>http://blog.youxu.info/2015/05/17/tech-lead-1/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2015/05/17/tech-lead-1/</guid>
			</item>
		
			<item>
				<title>编程珠玑番外篇-Q 协程的历史，现在和未来</title>
				<description>&lt;p&gt;&lt;span style=&quot;color: #808080&quot;&gt;&lt;em&gt;本文原发于《程序员》2014年11月刊，发表时略有修改。 &lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;从磁带到协程&lt;/h3&gt;

&lt;p&gt;COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 &lt;a href=&quot;https://www.cs.virginia.edu/brochure/images/manuals/b205/central/central.html&quot;&gt;Burroughs 205&lt;/a&gt; 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕&lt;/p&gt;

&lt;p&gt;以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 &lt;a href=&quot;http://www.antlr.org/&quot;&gt;ANTLR&lt;/a&gt; 构建的编译器，都遵循这样的设计。&lt;/p&gt;

&lt;p&gt;在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。&lt;/p&gt;

&lt;p&gt;以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。首先，从原理上来说，因为 COBOL 并不是 [&lt;span style=&quot;color: #808080&quot;&gt;&lt;em&gt;本文原发于《程序员》2014年11月刊，发表时略有修改。 &lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;从磁带到协程&lt;/h3&gt;

&lt;p&gt;COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 &lt;a href=&quot;https://www.cs.virginia.edu/brochure/images/manuals/b205/central/central.html&quot;&gt;Burroughs 205&lt;/a&gt; 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕&lt;/p&gt;

&lt;p&gt;以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 &lt;a href=&quot;http://www.antlr.org/&quot;&gt;ANTLR&lt;/a&gt; 构建的编译器，都遵循这样的设计。&lt;/p&gt;

&lt;p&gt;在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。&lt;/p&gt;

&lt;p&gt;以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。首先，从原理上来说，因为 COBOL 并不是](http://en.wikipedia.org/wiki/LL_parser) 型语法，即使现在我们也无法简单构建一个以词法分析为子过程的自动机。其次，当年计算机依赖于磁带存储设备，而磁带存储设备只支持顺序存储（设想一下随机访问带来的频繁的倒带和快进问题）。也就是说，依次执行编译步骤并依靠中间文件通信的设计是不现实的，各步骤必须同步前进。正是这样的现实局限和设计需要，自然催生了协程的概念。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;自顶向下，无需协同&lt;/h3&gt;

&lt;p&gt;虽然协程是伴随着高级语言诞生的，它却没有能像子过程一样成为通用编程语言的基本元素。&lt;/p&gt;

&lt;p&gt;从 1963 年首次提出到上个世纪九十年代，我们在 ALOGL, Pascal, C, FORTRAN 等主流的命令式编程语言中都没有看到原生的协程支持。协程只稀疏地出现在 Simula，Modular-2 (Pascal 升级版) 和 Smalltalk 等相对小众的语言中。协程作为一个比子进程更加通用的概念，在实际编程却没有取代子进程，这一点不得不说是出乎意外的。如果我们结合当时的程序设计思想看，这一点又是意料之中的：协程是不符合那个时代所崇尚的“自顶向下”的程序设计思想的，自然也就不会成为当时主流的命令式编程语言 (imperative programming) 的一部分。&lt;/p&gt;

&lt;p&gt;正如面向对象的语言是围绕面向对象的开发理念设计一样，命令式编程语言是围绕自顶向下(top-down)的开发理念设计的。在自顶向下的理念指导下，程序被切分为一个主程序和大大小小的子模块，每一个子模块又可能调用更多子模块等等。C 家族语言的 main() 函数就是这种自顶而下思想的体现。在这种理念指导下，各模块形成层次调用关系，而程序设计就是制作这些子过程。在“自顶向下”这种层次化的理念下，具有鲜明层次的子过程调用成为软件系统最自然的组织方式，也是理所当然。相较之下，具有执行中让出和恢复功能的协程在这种架构下无用武之地。可以说，自上而下的设计思想从一开始就排除了对协程的需求。其后的结构化编程(Structural Programming) 思想，更是进一步强化了“子过程调用作为唯一控制结构”的基本假设。在这样的指导思想下，协程一直没有成为当时编程语言的一等公民。&lt;/p&gt;

&lt;p&gt;尽管从提出到上世纪 90 年代，协程在编程语言中没有普遍成为一等公民，但作为一种易于理解的控制结构，协程的概念渗入到了软件设计的许多方面。在结构化编程思想一统天下之时， D. Knuth 曾经专门写过一篇 “&lt;a href=&quot;http://c2.com/cgi/wiki?StructuredProgrammingWithGoToStatements&quot;&gt;Structured Programming with GOTO&lt;/a&gt;” 来为 GOTO 语句辩护。在他列出的几条 GOTO 可以方便编程且不破坏程序结构的例子中，有一个（例子7b）就是用 GOTO 实现协程控制结构。相比较之下，不用 GOTO 的“结构化”代码反而失去了良好的结构。当然，追求实际结果的工业界对于学界的这场要不要剔除 GOTO 的争论并不感冒。当时许多语言都附带了不建议使用的 GOTO 语句，显得左右逢源。这方面一个最明显的例子就是 Java：其语言本身预留了 goto 关键字，其编译器却没有提供任何的支持，可以说在 goto 这场争论中做足了中间派。&lt;/p&gt;

&lt;p&gt;实践中，协程的思想频繁应用于任务调度和流处理上。比如，UNIX 管道就可以看成是众多命令间的协同操作。当然，管道的现代实现都是以 pipe() 系统调用和进程间的通信为基础，而非简单遵循协程的 yield/resume 语法。&lt;/p&gt;

&lt;p&gt;许多协同式多任务操作系统，也可以看成协程运行系统。说到协同式多任务系统，一个常见的误区是认为协同式调度比抢占式调度“低级”，因为我们所熟悉的桌面操作系统，都是从协同式调度（如 Windows 3.2， Mac OS 9 等）过渡到抢占式多任务系统的。实际上，调度方式并无高下，完全取决于应用场景。抢占式系统允许操作系统剥夺进程执行权限，抢占控制流，因而天然适合服务器和图形操作系统，因为调度器可以优先保证对用户交互和网络事件的快速响应。当年 Windows 95 刚刚推出的时候，抢占式多任务就被作为一大买点大加宣传。协同式调度则等到进程时间片用完或系统调用时转移执行权限，因此适合实时或分时等等对运行时间有保障的系统。&lt;/p&gt;

&lt;p&gt;另外，抢占式系统依赖于 CPU 的硬件支持。 因为调度器需要“剥夺”进程的执行权，就意味着调度器需要运行在比普通进程高的权限上，否则任何“流氓（rogue）”进程都可以去剥夺其他进程了。只有 CPU 支持了执行权限后，抢占式调度才成为可能。x86 系统从 80386 处理器开始引入 Ring 机制支持执行权限，这也是为何 Windows 95 和 Linux 其实只能运行在 80386 之后的 x86 处理器上的原因。而协同式多任务适用于那些没有处理器权限支持的场景，这些场景包含资源受限的嵌入式系统和实时系统。在这些系统中，程序均以协程的方式运行。调度器负责控制流的让出和恢复。通过协程的模型，无需硬件支持，我们就可以在一个“简陋”的处理器上实现一个多任务的系统。我们见到的许多智能设备，如运动手环，基于硬件限制，都是采用协同调度的架构。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;协程的复兴和现代形式&lt;/h3&gt;

&lt;p&gt;编程思想能否普及开来，很大程度上在于应用场景。协程没有能在自顶向下的世界里立足，却在动态语言世界里大放光彩，这里最显著的例子莫过于 Python 的迭代器和生成器。&lt;/p&gt;

&lt;p&gt;回想一下在 C 的世界里，循环的标准写法是 for (i = 0; i &amp;lt; n; ++i) { … }。 这行代码包含两个独立的逻辑, for 循环控制了 i 的边界条件， ++i 控制了 i 的自增逻辑。这行代码适用于 C 世界里的数组即内存位移的范式，因此适合大多数访问场景。到了 STL 和复杂数据结构的世界，因为许多数据结构只支持顺序访问，循环往往写成： for (i = A.first(); i.hasNext();i = i.next()) { … }&lt;/p&gt;

&lt;p&gt;这种设计抽象出了一个独立于数据结构的迭代器，专门负责数据结构上元素访问顺序。迭代器把访问逻辑从数据结构上分离出来, 是一个常用的设计模式 （GoF 23个设计模式之一）.我们在 STL 和 Java Collection 中也常常看到迭代器的身影。&lt;/p&gt;

&lt;p&gt;在适当的时候，我们可以更进一步引入一个语法糖（脚注：这里牵涉到一个外部迭代器和内部迭代器的问题。限于篇幅不在此讨论）将循环写成: for i in A.Iterator() {func(i)}。&lt;/p&gt;

&lt;p&gt;事实上，许多现代语言都支持类似的语法。这种语法抛弃了以 i 变量作为迭代指针的功能，要求迭代器自身能够记住当前迭代位置，调用时返回下一个元素。读者不难看到，这种架构就是我们在文章开始提到的语法分析器的架构。正因为如此，我们可以从协程的角度来理解迭代器：当控制流转换到迭代器上时，迭代器负责生成和返回下一个元素。一旦下一个元素准备就绪，迭代器就让出控制流。这种特殊的迭代器实现在 Python 中又被成为生成器。以协程的角度切入的的好处是设计大大精简。实际上，在 Python 中，生成器本身就是一个普通的函数，和普通函数的唯一不同是它的返回语句是协程风格的 yield。这里，yield 一语双关，既是让出控制流，也是生成迭代器的返回值。&lt;/p&gt;

&lt;p&gt;以上我们仅仅讨论了生成器的最基本的特性。实际上，生成器的强大之处在于我们可以像 UNIX 管道一样串联起来，组成所谓的生成器表达式。如果我们有一个可以生成 1，2，3 … 的生成器 N，则 square = (i **2 for i in N) 就是一个生成平方数的生成器表达式。注意这里圆括号语法和 [&lt;span style=&quot;color: #808080&quot;&gt;&lt;em&gt;本文原发于《程序员》2014年11月刊，发表时略有修改。 &lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;从磁带到协程&lt;/h3&gt;

&lt;p&gt;COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 &lt;a href=&quot;https://www.cs.virginia.edu/brochure/images/manuals/b205/central/central.html&quot;&gt;Burroughs 205&lt;/a&gt; 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕&lt;/p&gt;

&lt;p&gt;以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 &lt;a href=&quot;http://www.antlr.org/&quot;&gt;ANTLR&lt;/a&gt; 构建的编译器，都遵循这样的设计。&lt;/p&gt;

&lt;p&gt;在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。&lt;/p&gt;

&lt;p&gt;以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。首先，从原理上来说，因为 COBOL 并不是 [&lt;span style=&quot;color: #808080&quot;&gt;&lt;em&gt;本文原发于《程序员》2014年11月刊，发表时略有修改。 &lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;从磁带到协程&lt;/h3&gt;

&lt;p&gt;COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 &lt;a href=&quot;https://www.cs.virginia.edu/brochure/images/manuals/b205/central/central.html&quot;&gt;Burroughs 205&lt;/a&gt; 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕&lt;/p&gt;

&lt;p&gt;以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 &lt;a href=&quot;http://www.antlr.org/&quot;&gt;ANTLR&lt;/a&gt; 构建的编译器，都遵循这样的设计。&lt;/p&gt;

&lt;p&gt;在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。&lt;/p&gt;

&lt;p&gt;以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。首先，从原理上来说，因为 COBOL 并不是](http://en.wikipedia.org/wiki/LL_parser) 型语法，即使现在我们也无法简单构建一个以词法分析为子过程的自动机。其次，当年计算机依赖于磁带存储设备，而磁带存储设备只支持顺序存储（设想一下随机访问带来的频繁的倒带和快进问题）。也就是说，依次执行编译步骤并依靠中间文件通信的设计是不现实的，各步骤必须同步前进。正是这样的现实局限和设计需要，自然催生了协程的概念。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;自顶向下，无需协同&lt;/h3&gt;

&lt;p&gt;虽然协程是伴随着高级语言诞生的，它却没有能像子过程一样成为通用编程语言的基本元素。&lt;/p&gt;

&lt;p&gt;从 1963 年首次提出到上个世纪九十年代，我们在 ALOGL, Pascal, C, FORTRAN 等主流的命令式编程语言中都没有看到原生的协程支持。协程只稀疏地出现在 Simula，Modular-2 (Pascal 升级版) 和 Smalltalk 等相对小众的语言中。协程作为一个比子进程更加通用的概念，在实际编程却没有取代子进程，这一点不得不说是出乎意外的。如果我们结合当时的程序设计思想看，这一点又是意料之中的：协程是不符合那个时代所崇尚的“自顶向下”的程序设计思想的，自然也就不会成为当时主流的命令式编程语言 (imperative programming) 的一部分。&lt;/p&gt;

&lt;p&gt;正如面向对象的语言是围绕面向对象的开发理念设计一样，命令式编程语言是围绕自顶向下(top-down)的开发理念设计的。在自顶向下的理念指导下，程序被切分为一个主程序和大大小小的子模块，每一个子模块又可能调用更多子模块等等。C 家族语言的 main() 函数就是这种自顶而下思想的体现。在这种理念指导下，各模块形成层次调用关系，而程序设计就是制作这些子过程。在“自顶向下”这种层次化的理念下，具有鲜明层次的子过程调用成为软件系统最自然的组织方式，也是理所当然。相较之下，具有执行中让出和恢复功能的协程在这种架构下无用武之地。可以说，自上而下的设计思想从一开始就排除了对协程的需求。其后的结构化编程(Structural Programming) 思想，更是进一步强化了“子过程调用作为唯一控制结构”的基本假设。在这样的指导思想下，协程一直没有成为当时编程语言的一等公民。&lt;/p&gt;

&lt;p&gt;尽管从提出到上世纪 90 年代，协程在编程语言中没有普遍成为一等公民，但作为一种易于理解的控制结构，协程的概念渗入到了软件设计的许多方面。在结构化编程思想一统天下之时， D. Knuth 曾经专门写过一篇 “&lt;a href=&quot;http://c2.com/cgi/wiki?StructuredProgrammingWithGoToStatements&quot;&gt;Structured Programming with GOTO&lt;/a&gt;” 来为 GOTO 语句辩护。在他列出的几条 GOTO 可以方便编程且不破坏程序结构的例子中，有一个（例子7b）就是用 GOTO 实现协程控制结构。相比较之下，不用 GOTO 的“结构化”代码反而失去了良好的结构。当然，追求实际结果的工业界对于学界的这场要不要剔除 GOTO 的争论并不感冒。当时许多语言都附带了不建议使用的 GOTO 语句，显得左右逢源。这方面一个最明显的例子就是 Java：其语言本身预留了 goto 关键字，其编译器却没有提供任何的支持，可以说在 goto 这场争论中做足了中间派。&lt;/p&gt;

&lt;p&gt;实践中，协程的思想频繁应用于任务调度和流处理上。比如，UNIX 管道就可以看成是众多命令间的协同操作。当然，管道的现代实现都是以 pipe() 系统调用和进程间的通信为基础，而非简单遵循协程的 yield/resume 语法。&lt;/p&gt;

&lt;p&gt;许多协同式多任务操作系统，也可以看成协程运行系统。说到协同式多任务系统，一个常见的误区是认为协同式调度比抢占式调度“低级”，因为我们所熟悉的桌面操作系统，都是从协同式调度（如 Windows 3.2， Mac OS 9 等）过渡到抢占式多任务系统的。实际上，调度方式并无高下，完全取决于应用场景。抢占式系统允许操作系统剥夺进程执行权限，抢占控制流，因而天然适合服务器和图形操作系统，因为调度器可以优先保证对用户交互和网络事件的快速响应。当年 Windows 95 刚刚推出的时候，抢占式多任务就被作为一大买点大加宣传。协同式调度则等到进程时间片用完或系统调用时转移执行权限，因此适合实时或分时等等对运行时间有保障的系统。&lt;/p&gt;

&lt;p&gt;另外，抢占式系统依赖于 CPU 的硬件支持。 因为调度器需要“剥夺”进程的执行权，就意味着调度器需要运行在比普通进程高的权限上，否则任何“流氓（rogue）”进程都可以去剥夺其他进程了。只有 CPU 支持了执行权限后，抢占式调度才成为可能。x86 系统从 80386 处理器开始引入 Ring 机制支持执行权限，这也是为何 Windows 95 和 Linux 其实只能运行在 80386 之后的 x86 处理器上的原因。而协同式多任务适用于那些没有处理器权限支持的场景，这些场景包含资源受限的嵌入式系统和实时系统。在这些系统中，程序均以协程的方式运行。调度器负责控制流的让出和恢复。通过协程的模型，无需硬件支持，我们就可以在一个“简陋”的处理器上实现一个多任务的系统。我们见到的许多智能设备，如运动手环，基于硬件限制，都是采用协同调度的架构。&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;协程的复兴和现代形式&lt;/h3&gt;

&lt;p&gt;编程思想能否普及开来，很大程度上在于应用场景。协程没有能在自顶向下的世界里立足，却在动态语言世界里大放光彩，这里最显著的例子莫过于 Python 的迭代器和生成器。&lt;/p&gt;

&lt;p&gt;回想一下在 C 的世界里，循环的标准写法是 for (i = 0; i &amp;lt; n; ++i) { … }。 这行代码包含两个独立的逻辑, for 循环控制了 i 的边界条件， ++i 控制了 i 的自增逻辑。这行代码适用于 C 世界里的数组即内存位移的范式，因此适合大多数访问场景。到了 STL 和复杂数据结构的世界，因为许多数据结构只支持顺序访问，循环往往写成： for (i = A.first(); i.hasNext();i = i.next()) { … }&lt;/p&gt;

&lt;p&gt;这种设计抽象出了一个独立于数据结构的迭代器，专门负责数据结构上元素访问顺序。迭代器把访问逻辑从数据结构上分离出来, 是一个常用的设计模式 （GoF 23个设计模式之一）.我们在 STL 和 Java Collection 中也常常看到迭代器的身影。&lt;/p&gt;

&lt;p&gt;在适当的时候，我们可以更进一步引入一个语法糖（脚注：这里牵涉到一个外部迭代器和内部迭代器的问题。限于篇幅不在此讨论）将循环写成: for i in A.Iterator() {func(i)}。&lt;/p&gt;

&lt;p&gt;事实上，许多现代语言都支持类似的语法。这种语法抛弃了以 i 变量作为迭代指针的功能，要求迭代器自身能够记住当前迭代位置，调用时返回下一个元素。读者不难看到，这种架构就是我们在文章开始提到的语法分析器的架构。正因为如此，我们可以从协程的角度来理解迭代器：当控制流转换到迭代器上时，迭代器负责生成和返回下一个元素。一旦下一个元素准备就绪，迭代器就让出控制流。这种特殊的迭代器实现在 Python 中又被成为生成器。以协程的角度切入的的好处是设计大大精简。实际上，在 Python 中，生成器本身就是一个普通的函数，和普通函数的唯一不同是它的返回语句是协程风格的 yield。这里，yield 一语双关，既是让出控制流，也是生成迭代器的返回值。&lt;/p&gt;

&lt;p&gt;以上我们仅仅讨论了生成器的最基本的特性。实际上，生成器的强大之处在于我们可以像 UNIX 管道一样串联起来，组成所谓的生成器表达式。如果我们有一个可以生成 1，2，3 … 的生成器 N，则 square = (i **2 for i in N) 就是一个生成平方数的生成器表达式。注意这里圆括号语法和](http://en.wikipedia.org/wiki/List_comprehension) 方括号语法的区别，square = [i **2 for i in N] 是生成一个具体的列表。我们可以串联这些生成器表达式，最终的控制流会在这些串联的部分间转换，无需我们写作复杂的嵌套调用。当然，yield 只是冰山的一角，现代的 Python 语言还充分利用了 yield 关键字构建了 &lt;a href=&quot;https://www.python.org/dev/peps/pep-0380/&quot;&gt;yield from&lt;/a&gt; 语句，(yield) 语法等等，使得我们无困难的将协程的思想融入到 Python 编程中去。限于篇幅这里不再展开。&lt;/p&gt;

&lt;p&gt;我们前面说过，协程的思想本质上就是控制流的主动让出和恢复机制。在现代语言里，可以实现协程思想的方法很多，这些实现间并无高下之分，所区别的就是是否适合应用场景。理解这一点，我们对于各种协程的分类，如半对称/对称协程，有栈与无栈协程等具体实现就能提纲挈领，无需在实现细节上纠结。&lt;/p&gt;

&lt;p&gt;协程在实践中的实现方式千差万别，一个简单的原因，是协程本身可以通过许多基本元素构建。基本元素的选取方式不一样，构建出来的协程抽象也就有差别。比如, Lua 语言选取了 create, resume 和 yield 作为基本构建元素, 从调度器层面构建出所谓的“非对程”协程系统。而 Julia 语言绕过调度器，通过在协程内调用 yieldto 函数完成了同样的功能，构建出了一个所谓的对称协程系统。尽管这两个语言使用了同样的 setjmp 库，构造出来的原语却不一样。又比如，许多 C 语言的协程库都使用了 ucontext 库实现，这是因为 POSIX 本身提供了 ucontext 库，不少协程实现是以 ucontext 为蓝本实现的。这些实现，都不可避免地带上了 ucontext 系统的一些基本假设，比如协程间是平等的，一般带有调度器来协调协程等等（比如 &lt;a href=&quot;http://swtch.com/libtask/&quot;&gt;libtask&lt;/a&gt; 实现，以及&lt;a href=&quot;http://blog.codingnow.com/2012/07/c_coroutine.html&quot;&gt;云风的 coroutine 库&lt;/a&gt;）。Go 语言的一个鲜明特色就是通道（channel）作为一级对象。因此，resume 和 yield 等在其他语言里的原语在 go 里都以通道方式构建。我们还可以举出许多同样的例子。这些风格的差异往往和语言的历史，演化路径，和要解决的问题相关，我们不必苛求他们的协程模型一定要如此这般。&lt;/p&gt;

&lt;p&gt;总的来说，协程为协同任务提供了一种运行时抽象。这种抽象非常适合于协同多任务调度和数据流处理。在现代操作系统和编程语言中，因为用户态线程切换代价比内核态线程小，协程成为了一种轻量级的多任务模型。我们无法预测未来，但是可以看到，协程已经成为许多擅长数据处理的语言的一级对象。随着计算机并行性能的提升，用户态任务调度已经成为一种标准的多任务模型。在这样的大趋势下，协程这个简单且有效的模型就显得更加引人注目。&lt;/p&gt;
</description>
				<pubDate>Thu, 04 Dec 2014 00:10:52 +0000</pubDate>
				<link>http://blog.youxu.info/2014/12/04/coroutine/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2014/12/04/coroutine/</guid>
			</item>
		
			<item>
				<title>编程珠玑番外篇-P PostScript 语言里的珠玑</title>
				<description>&lt;p dir=&quot;ltr&quot;&gt;
  &lt;span style=&quot;color: #808080&quot;&gt;&lt;em&gt;本文原发于《程序员》2014年6月刊，发表时略有修改。 &lt;/em&gt;&lt;/span&gt;
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  首位 ACM 图灵奖得主  Alan Perlis 曾说过：“&lt;em&gt;如果一门编程语言不能影响你的思维，就没有学的必要&lt;/em&gt;’。尽管能通过这个严苛测试的语言稀稀朗朗，在我看来，PostScript 在这个测试中至少得 A。作为一个着重于平面出版应用的领域特定语言(DSL)，PostScript 彻底地改变了桌面出版行业。除此之外，PostScript 还是一个设计简单但功能强大的编程语言，含有许多至今仍可以借鉴的珠玑。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  &lt;strong&gt;PostScript 的领域对象和操作&lt;/strong&gt;
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  作为针对桌面出版的文档描述语言，PostScript 的设计者力图要解决的核心问题，是如何设计一个灵活高效的语言，以操控桌面出版里各种各样的图形对象，并保证设备无关性。我们不妨戴上语言设计者的眼镜，来模拟一下这个过程。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  我们面临的首要问题是如何来描述桌面出版里的种种复杂对象和操作。尽管任何平面出版物最终都是二维像素点的集合，我们并不希望这个语言局限于描述像素点的颜色。这个语言最好能够直接描述文字，线条，形状等设计师熟悉的对象。因为从根本上讲，如果我们要设计的描述语言没有足够的表达能力，不能够精简高效地表达图片，字体，形状，颜色等桌面出版领域的业务对象，这个语言将不可避免地“难用”。一般来说，把领域特定语言设计得“好用”，需要深厚的领域知识 (domain knowledge)。所幸的是， PostScript 的设计者们，原先在施乐 PARC 从事激光打印机控制语言设计，对于桌面出版可算驾轻就熟。因此，他们毫不费力地选取了  &lt;a href=&quot;http://en.wikipedia.org/wiki/B%C3%A9zier_curve&quot;&gt;Bézier&lt;/a&gt; 曲线，矢量字体，绘图路径(Path) 等作为整个绘图系统的基本结构。在对这些对象的操作上，PostScript 选取了平移，旋转，放缩等仿射变换，加上路径操作和字体控制，构成了一个强大但规整的绘图系统。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  PostScript 绘图系统的设计深刻影响了后来的许多矢量图形系统。举例说，如今计算机使用的矢量字体均采用 &lt;a href=&quot;http://en.wikipedia.org/wiki/B%C3%A9zier_curve&quot;&gt;Bézier&lt;/a&gt;  曲线描述，即起源于 PostScript；如今几乎所有的矢量绘图语言都支持的“路径”，也起源于 PostScript。我们不在此详细展开这些领域对象选取背后的原因。对 PostScript 感兴趣的读者可以阅读 PostScript Language Tutorial &amp;amp; Cookbook (也称 Bluebook) 以了解 PostScript 的一些基本概念。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  &lt;strong&gt;PostScript 的语言设计&lt;/strong&gt;
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  基本领域对象确定后，我们就可以换上计算机语言设计者的帽子，力求设计出一个“灵活高效”和“设备无关”的语言来控制这些领域对象。设计目标落实为具体需求，包含以下三个。第一，语言本身要能够表达曲线，字体，图片，形状等等领域对象；如颜色，分页以及这些对象的平移旋转等操作，在语言里最好也都是一等公民，能够直接表达。第二，语言的表达能力要足够强大，最好是图灵完全的，以支持现实中灵活的需求。第三，语言要与设备无关，也就是说，语言将运行在一个虚拟机或解释器上，而非直接编译为二进制代码。考虑到我们要设计的语言是针对桌面出版的，最终还要加上一条：这个语言的语法和结构要足够简单，使得非编程专业人士也能使用。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  有了需求的指导，我们不难理解 PostScript 所采取的设计：以一个易用的，图灵完全的语言作为蓝本，加入众多针对桌面出版的对象操作，并实现一个轻量的，与设备无关的解释器。事实上，PostScript 是以 FORTH 语言作为蓝本设计的。选取 FORTH 的主要原因，是因为它是一个轻量级的，基于栈虚拟机的语言。FORTH 的表达能力和易用性当时已经被实践所证明，因此借用它的基本控制语法就是一个很自然的选择。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  &lt;strong&gt;逆波兰表示法和度量单位&lt;/strong&gt;
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  逆波兰表示法是 FORTH 和 PostScript 等基于栈的语言的一个鲜明特点。在 ALGOL 家族语言中，3乘以4的一般写法是 3 * 4，即运算符中缀。PostScript 将运算符后缀，写作 “3 4 mul”。意思是将 3, 4 分别推入栈中，然后将乘法(multiply) 操作运用于两个栈顶元素（弹出），并将乘积结果入栈。FORTH 仍然采用 + * 等数学符号。PostScript 规范化了所有的操作符，一致采用 add, mul 等单词操作符来代替 +, * 等传统的中缀操作符。我们将稍后阐明规整化的优点。这里我们只需要了解一点： PostScript 程序本质上是一个后缀表达式。PostScript  没有所谓的语法，只有栈操作。如果非要说有语法，那就是逆波兰表示法。这一点非常类似于 LISP：所谓的语法，就是 S 表达式。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  PostScript 允许以闭包定义新操作符，其中，闭包是放在 {} 中的后缀表达式。比如，“乘以3”这个操作可定义为: /mul3 { 3 mul } def。这里，/mul3 表示取 “mul3” 的符号值。{ 3 mul } 是一个闭包，而 def 将 mul3 这个符号，映射到 { 3 mul } 闭包。据此，4 mul3 即为 4 3 mul。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  其实，从语法上来看，/mul3 { 3 mul } def 和 3 4 mul 并没有明显的不同：都是前两个操作元入栈，最后一个操作符进行运算。也就是说，PostScript 的栈是异构的，符号，数字和闭包都可以放入栈中。许多操作符如 if ，也依赖于栈上有一个布尔值和一个闭包。这种不在栈中区分代码和数据的设计，允许我们重写栈上的闭包。实际上我们可以证明这个特性等价于 LISP 里的宏 (Macro) 的表达能力，限于篇幅我们不仔细展开。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  现在，我们从这个 mul3 这个平淡无奇的例子出发，定义一个英寸 (inch) 的操作符： /inch {72 mul} def。一眼看去，{72 mul} 是闭包，而 inch 是长度单位，两者毫不相干，为何强拉在一起？ 原来，PostScript 的基本长度单位是 1/72 英寸，因此 5 inch 即为展开为 5 72 mul, 或者说 360 个基本单位。Inch 的定义使得我们可以书写 1.2 inch 2.3 inch moveto 这样直观的程序。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  用闭包定义常用度量单位在 PostScript 中并不少见。对于从未接触过这种定义方法的读者来说，相信 inch 这个例子让人印象深刻，因为它昭示了度量单位的实质：度量单位是后缀闭包。比如我们说 10 美元的时候，已经在自觉或不自觉地将“美元”单位替换成 {汇率 mul} 闭包，换算成 60 人民币等。实际上，任何度量单位之所以能够被我们感知，都是因为我们脑中的一个潜在后缀闭包的作用。在摄氏度体系下的人对华式温度没有感觉，或者仅接触一定数量级范围内的人对大数字不敏感，都是一个原因：我们尚未建立一个将不熟悉的单位或数量级转化为可感知的单位或数量级的闭包。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  &lt;strong&gt;PostScript 的运行时字典栈&lt;/strong&gt;
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  除了基本控制语法外，PostScript 引入了对于图形处理很重要的两个基本数据结构：字典和数组。可以想像，存有一系列点的数组可以表达一个字符的轮廓，而字典可以很好地表达一套字体。不仅如此，通过字典栈这个概念，PostScript 具有了 FORTH 和其他栈语言所完全不具有的动态特性。我们仍然以一个例子说明。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  我们定义一个求直角三角形斜边长度的操作 hyp，即 /hyp { dup mul exch dup mul add sqrt } def （这里 dup 表示重复栈顶元素，exch 表示交换栈顶两元素，sqrt为平方根，读者可以自行验证这个函数的正确性）。 这里， 3 4 hyp 得到 5。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  对于解释器来说，我们新定义的 hyp 与 mul 并没有本质的不同（后缀表达式和规则化带来的便利）。解释器处理这些操作符时，无论是语言预先定义的还是用户定义的，不可避免的需要进行符号表查找。可能的区别仅是到不同的符号表里查找。进一步说，一个叫 inch 的符号在没有进行符号表查找之前，我们根本不能确定这究竟是一个变量，还是一个闭包。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  为了一致地处理符号表的查找操作， PostScript 引入了字典栈 (dictionary stack) 的概念。字典栈是一个由解释器维护的栈，而栈中的元素则是作为符号表的字典。解释器启动后，系统字典 systemdict 中含有所有预定义操作符和变量，如 add, mul 等。用户字典 userdict 将涵盖自定义的操作符和变量。用户也可以随时建立新的字典插入字典栈中。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  以字典方式存储符号表是容易理解的，可是为什么需要把这些字典加入“栈”中呢？原来，PostScript 是按栈的顺序在字典中寻找操作符的。假如定义 “/mul {add round} def”，则当前字典里的 mul 会被优先使用，而系统定义的 mul 不再可见。乍一看之下，这和面向对象语言里提到的运算符重载概念类似。实质上，PostScript 的设计灵活许多。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  首先，因为字典栈的存在，每个运算符都自动有了作用域（预定义的运算符因为存在于 systemdict 中从而有全局作用域）。通过字典栈，我们可以实现其他语言中的 lambda 表达式或者 Java 中的匿名内部类。PostScript 的运算符本质上是动态作用域的，但因为字典栈的存在，我们可以轻松实现词法作用域，方法即是在作用域中临时定义一个字典，在字典中定义新的操作符，并将字典推入字典栈。这样，只要在作用域结束时弹出临时字典，操作符定义也随之撤销。许多 PostScript 程序都采用这种方法构建用户自定义操作符：用户可以局部重定义分页操作符 showpage 以进行页面计数，局部重定义错误处理操作符 handleerror 处理异常等等。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  其次，字典栈巧妙地支持了局部变量。和闭包一样，局部变量的本质是有作用域的值。基于栈的语言对函数局部变量是不友好的，因为局部变量本身是对处理器寄存器的抽象，访问局部变量也是采取随机存取而非按栈顺序存取的方式。而栈机器本身不直接支持寄存器抽象。熟悉 JVM 的读者都知道，JVM 的 {a,i,l,f,d}{load,store} 系列指令，非常繁冗地支持局部变量数组和栈之间的转存。在字典栈中，局部变量有了优雅的解决方法：通过建立临时字典，我们可以在不引入复杂的转存操作下随机存取随机变量，而且局部变量的作用域得到了保障。比如，以下程序定义了一个叫做 localvariable 的局部变量，作用域仅限于 /sampleproc。而将 something 换成 {something} 闭包，即是一个局部的操作符定义。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p dir=&quot;ltr&quot;&gt;
  /sample_proc
&lt;/p&gt;

  &lt;p dir=&quot;ltr&quot;&gt;
   { 1 dict begin % 定义一个大小为1的临时字典
&lt;/p&gt;

  &lt;p dir=&quot;ltr&quot;&gt;
  /local_variable something def
&lt;/p&gt;

  &lt;p dir=&quot;ltr&quot;&gt;
      end   % begin end 之间为字典元素
&lt;/p&gt;

  &lt;p dir=&quot;ltr&quot;&gt;
      &amp;#8230;   % 具体的函数定义
&lt;/p&gt;

  &lt;p dir=&quot;ltr&quot;&gt;
   } def
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  &lt;strong&gt;PostScript 和语言的 Annotation&lt;/strong&gt;
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  因为 .ps 文件本质是一个程序而非文档，打印 PostScript 文件的过程实质上是调用 PostScript 解释器执行程序的过程。因为 PostScript 的图灵完全性，在 PostScript 程序执行完之前我们对文档的结构信息，比如一共多少页，文档有没有彩色元素等等结构化的信息一无所知。PostScript 设计于在桌面出版业未起步时，因此仅仅关心绘制控制，并未考虑到如何表示这些结构信息，这样的缺憾是可以理解的。HTML 语言也经过了这样的道路：早期引入 FONT BIG 这种纯展示标签，而如今最佳实践是将结构信息放入 HTML，而将格式信息交给 CSS。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  因为 PostScript 的成功，越来越多的人希望作为桌面出版标准格式的 PostScript 能够包含文档结构信息。比方说，如果打印管理系统能够在将 PostScript 任务交给打印机之前知道文档的页数，就可以更好的调度打印任务，或者按页面收取费用等。这些关于文档的结构信息并不影响页面的展示，却是文档不可或缺的一部分。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  为解决这个问题，PostScript 用户自发地定义了一种通过注释表示文档结构信息的方法。比如，在一个10页的文档开头加入 %%Pages: 10，每一页的开始加入 %% Page N 等等。因为是注释，PostScript 解释器可以选择忽略它，而其他程序则可以据此管理文档。许多桌面出版软件也采取这样的方法写入作者，创建日期等信息。在强大的需求和既定行业标准的驱动下，Adobe 终于决定标准化这些用来表征文档结构的注释，发布了一系列的“文档结构约定(Document Structuring Conventions)”。之所以叫约定，因为木已成舟，无法强行要求每个 PS 文档管理器或打印机都遵守标准。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  DSC 使得静态结构检查变得可能。前文提到，PostScript 语法就一种——后缀表达式，静态语法检查并没有意义，而正确性检查却又非常难。引入文档结构约定后，我们就有条件检查一些约束，比如在宣称的描述一页的区块之内没有非法的分页操作等。DSC 不影响现有语言逻辑，却引入了新的语义正确性约束。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  DSC 这种引入新的元信息以静态检查程序的语义正确性的思想非常有前瞻性。可惜的是，因为了解 PostScript 的人较少，这样的思想没能在其他语言中实现。Java 5.0 才正式引入了 annotation 的概念，用 @override 这样的标记帮助编译器检查方法多态。Python 2.2 引入 classmethod， instancemethod 等 decorator 以检查方法的定义，而 C++ 最近才正式支持 annotation。这些比程序本身要抽象的元信息，越来越多地成为了自动分析工具的帮手。在 Google，我们采用一套线程安全的标记以帮助编译器静态检查代码的线程安全性。所有的这些，都成了提升开发效率的好帮手。以文档标记等方式记录元信息的思想可以追溯到 D.E. Knuth 的文学编程 (Literate Programming)，而 PostScript，是我所知的第一个以元信息约束程序语义的编程语言。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  &lt;strong&gt;其他一些有趣的历史&lt;/strong&gt;
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  PostScript 语言的历史很有趣也很能给人启发，限于篇幅我仅录几则。首先，PostScript 其实和 Smalltalk 很相似。因为同样出自于施乐 PARC 的研究，PostScript 语言风格受到 Smalltalk 影响很大。比如闭包的设计，if 和 repeat 语法的设计，几乎就是 Smalltalk 的翻版，仅在运算符顺序上有区别。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  Adobe 的几位创始人从 PARC 独立出来后，最初力图开发一套打印机控制语言。熟悉这几位创始人的 Steve Jobs 认为，这个语言最重要的任务不是控制打印机，而是制作高品质文档。在 Jobs 的推动下， Adobe 开发了一套可以支持 Apple 当时正在开发的 LaserWriter 激光打印机产出高品质文档的语言: PostScript。从此，Adobe 这家毫不起眼的小公司一举成为桌面出版革命最大的受益者。
&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  因为 PostScript 语言灵活复杂，解释 PostScript 语言需要强大的微处理器。为此，Apple LaserWriter 携带了一颗 12 MHz Motorola 68000 处理器。而同时期的，与之相连的 Machintosh 携带的是一颗 8MHz 的 Motorola 68000。打印机处理器比主机的强大，用现在的眼光看是不可思议。桌面出版的革命来得如此之快，需要的计算能力如此之大，是个人计算机行业所没有预见的。或许，未来的 3D 打印技术或量子传输技术 (Star Trek transporter) ，会让这种情况重新出现。
&lt;/p&gt;
</description>
				<pubDate>Tue, 10 Jun 2014 15:04:53 +0000</pubDate>
				<link>http://blog.youxu.info/2014/06/10/postscript/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2014/06/10/postscript/</guid>
			</item>
		
			<item>
				<title>编程珠玑番外篇-O 中间语言和虚拟机漫谈</title>
				<description>&lt;p&gt;&lt;em&gt;本文原发于《程序员》2014年3月刊&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;导言&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;编程语言的发展历史，总的来说，是一个从抽象机器操作逐步进化为抽象人的思维的过程。机器操作和人的思维如一枚硬币的两面，而语言编译器就像是个双面胶，将这两面粘在一起，保证编程语言源程序和机器代码在行为上等价。当然，人本身并不是一个完美的编译器，不能无错的将思维表达为高级语言程序，这种偏差，即Bug。因为编译器的帮助，我们可以脱离机器细节，只关心表达思维和程序行为这一面。&lt;/p&gt;

&lt;p&gt;编程语言的发展日新月异。特别是随着对问题的深入理解，新的设计思想，语法构建和新的领域相关语言（DSL）层出不穷。而硬币的另一面似乎一直波澜不惊。这是自然的——无需关心底层架构的变化，或者目标代码生成优化等技术的进化，正是编译器带给我们的好处，因为这些细节和要解决的问题往往关系不大。&lt;/p&gt;

&lt;p&gt;尽管所受的关注度不高，这些底层的技术一直在持续地进步。特别是这十年来，一场大的变革正在悄悄发生。这场变革，就是中间语言和虚拟机几乎成为了编程语言的标配——编译器不再以机器的CPU指令集作为编译目标，而是生成针对某种中间语言或虚拟机指令集的目标代码。这场变化是深刻的，它意味着编程语言的设计者自此完全脱离了具体硬件平台的束缚，语言如何设计和如何执行成为了两个完全正交的系统。这个变革大幅度降低了创造一个新语言的成本，一下子把我们推入了一个语言井喷的时代。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;从抽象语法树到中间语言&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;熟悉编译器设计的读者都知道，编译的第一步是构建一个叫抽象语法树(AST)的数据结构 (脚注: 语法树这个概念来源于 LISP)。有了这样的数据结构后，解释器和编译器在此分野。以 AST为起点，解释器完全可以遍历语法树，递归执行每个子结点。IEEE POSIX (或称标准UNIX) 规定的 AWK 语言，其经典实现就是一个生成和遍历语法树的过程：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;syminit();&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;compile_time = 1;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Node *winner ; /* root of parse tree */&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;yyparse(); /* generate parse tree */&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;if (errorflag == 0) {&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;compile_time = 0; /* switch to execution */&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;run(winner); /* execution of parse tree starts here */&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Awk 这样的传统解释器的优点在于结构简单，开发便利。事实上许多领域专用语言都采取这种方式实现，如 PostScript, Matlab, R 等。&lt;/p&gt;

&lt;p&gt;解释执行的缺点也是显而易见的。首要的一点就是每次执行都需要重新生成语法树。领域专用语言或许可以忍受每次零点几秒的重复解释过程，而对于可以开发大型应用的通用编程语言来说，这一点是致命的。每次重新生成语法树也意味着这样的语言难以用于资源受限系统，因为&lt;/p&gt;

&lt;p&gt;语言本身语法结构复杂，布置一个解释模块的代价往往非常高昂。为了避免解释执行的这些弊端，传统的编译器致力于只解释一次，将通用语言的语法树，直接转变为目标机器的 CPU 指令。传统的 FORTRAN 和 C 编译器就是如此设计的。有些编程构建，如 C 语言中的 i++, 甚至是直接受 CPU 指令影响的产物。&lt;/p&gt;

&lt;p&gt;上个世纪 80 年代后期，随着对程序效率优化和 LISP 机器的研究，研究者们认识到，其实传统的编译和解释并不是对立的概念。特别的，编程语言的语法树转变可以为一种中间指令格式。这种中间指令格式贴近机器指令，可以进行运行效率优化。传统的以生成目标指令的编译器，可以将中间语言简单转为机器指令。而解释器，也省却了多次的语法树生成，而直接解释相对简单的中间语言。&lt;/p&gt;

&lt;p&gt;较早在中间语言上进行探索的是 MIT 的 LISP 机器。如 Thomas Knight，他的研究集中在如何在硬件上实现一个高效的 LISP 环境。显然，没有一个硅片可以直接运行 mapcar，但设计一个支持 mapcar 的中间语言并不困难，只需要支持一些基本的列表操作即可。这种设计思想影响了很多后来的系统。流行的 GCC 编译器，从结构上来说分前端和代码生成端两部分。连接两者的中间语言 RTL 的基本一些指令，都可以追溯到 LIPS 机器的指令集。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中间语言和虚拟机&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;中间语言可用于程序优化的原因是显而易见的：这种中间格式既贴近机器代码，又保存了原有程序的结构。程序优化并不是一门魔术。像循环展开，死代码消除等技术，都依赖于程序控制结构，而中间语言可以保持这样的控制结构。事实上，目前我们所知的编译优化技术，无一不是建立在结构分析之上。中间语言的出现让程序优化成为了一个独立的问题。原本单列的 C 程序优化, FORTRAN 程序优化如今统一归结为 RTL 程序优化。编译器前端可以千差万别支持许多语言，但负责优化和翻译为目标代码的后端均归为一个，就此一点，就大大简化了语言编译器的设计门槛。现如今，几乎没有一个语言设计者需要考虑如何生成高效目标代码了。&lt;/p&gt;

&lt;p&gt;当然，中间语言的作用并不仅限于目标代码优化。如果我们把中间语言也当作一种语言的话，不难发现中间语言甚至比原语言更加普及。 比如，Java 虚拟机(JVM) 语言实际上是一个比 Java 语言成功许多倍的产品。JVM 存在于众多Java 语言不存在的地方。像 Jython, Scala 和 JRuby 这样的语言，均依赖于 JVM, 而非 Java 语言本身。&lt;/p&gt;

&lt;p&gt;语言的虚拟机的本质，是一个可以运行中间语言的机器。 在实际硬件上，程序和数据是两个截然不同的概念；而对于虚拟机来讲，中间语言程序，只是虚拟机程序的输入数据罢了。这种将程序当作数据的处理方式，带来了我们熟知的许多虚拟机的优点，如跨平台特性，安全性等等。 因为程序即是数据，为虚拟机读取中间语言程序方便，其指令往往都是以字节为单位，故称为字节码 (bytecode)。 相比之下，计算机的 CPU 指令则可长度不一，也不一定占据整数个字节。&lt;/p&gt;

&lt;p&gt;程序是数据这个特性使得虚拟机可以做到跨平台和沙箱安全；反过来，数据是程序又使得虚拟机可以用在一些意想不到的地方，使数据更加灵活。 目前通行的轮廓字体描述语言 TrueType 就是成功运用虚拟机来更加灵活地处理字体的一个例子。&lt;/p&gt;

&lt;p&gt;TrueType 是一种采用数学函数描述字体的矢量字体。 矢量字体在理论上可以自由缩放。而实践中，因为显示器本质上是点阵的，所有的矢量字形都要经过栅格化 （rasterization） ， 将矢量轮廓近似转化为像素点的透明度。 然而，这种近似并不是随意的。 以汉字 “中” 为例，为保证其对称美观，我们必须约束栅格化程序，保证任何时候左右两个竖线与中间一竖的距离相等，哪怕为此不惜将此字缩减或放宽一两个像素。 这类约束又被称作提示 (hinting)。 它对于字体至关重要—缺少提示的矢量字体在字形较小时不可避免地会出现失真，变形和锯齿等现象。 不难理解，本质上“提示”是一个以字体轮廓和字形大小为输入，以栅格数据为输出的程序。 因为此，TrueType 包含了一套虚拟机指令，方便字体设计者表达这种提示。 可以想象，如果没有这个虚拟机的存在，设计灵活的矢量字体是不可能完成的任务。 实际上，我们所见到的几乎所有的矢量字体文件，都是一个数据和程序的混合物。 从另一方面来说，每个字形都需要一个专门的“提示”，也从一个侧面说明了设计高质量的中文字体之难度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基于栈，还是基于寄存器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;凡提到虚拟机，绕不过去的第一个问题就是这个虚拟机是基于栈的，还是基于寄存器的（有些虚拟机，如 LISP 机器，可以同时有栈和寄存器）？ 尽管这里“寄存器”和“栈”，都不一定直接对应到机器CPU的寄存器或者内存里的栈。这个问题之所以重要，因为它直接决定了虚拟机的应用场景。一般说来，基于栈的虚拟机结构相对简单，且更加适合资源受限系统。 比如上文我们说的 TrueType 虚拟机，结构简单，功能专一，就是基于栈的。&lt;/p&gt;

&lt;p&gt;尽管所有的计算机的存储模型都是构建在图灵机的无穷纸带模型上，实践中所有语言都或多或少依赖于栈模型。特别的，函数调用就等价于栈的推入和弹入操作，其他操作均可抽象为对栈顶元素进行。相比之下，寄存器模型虽然贴近真实机器，却并不够直接：很少有高级语言直接制定寄存器如何分配的，因此编译器的作者需要考量寄存器分配问题。而基于栈的虚拟机的所有指令都可默认为对栈顶元素操作，结构简单，且暂时绕开了寄存器分配难题。&lt;/p&gt;

&lt;p&gt;基于栈的虚拟机更加适合内存和 CPU 处理速度等方面有限的系统。同样的源程序，在目标代码的体积上，面向栈虚拟机上生成的代码更加小。这是容易理解的：基于栈的虚拟机的指令默认对栈顶元素操作，因此指令只需为 OP 格式，无需 OP Reg1, Reg2, Reg3 等额外指定寄存器。这个设计也绕开了指令解码问题。平均上说，基于寄存器的虚拟机生成的指令的体积比基于栈的要大。我们见到的许多基于栈的虚拟机，都是为资源受限系统设计的。JVM 的初衷是一个运行在电视机顶盒中的小系统，后来精简版本的 JVM 甚至可以放到智能卡上；Forth 语言的虚拟机是要用在计算机固件(Open Firmware)，航空系统和嵌入式系统中；控制打印的 Postscript 是用于高品质打印机中。很显然，机顶盒，引导固件和打印机都是资源受限的系统，这些系统中的虚拟机，不约而同都是基于栈的。值得一提的是，因为实现简单，许多并非用于受限系统的通用语言的虚拟机也是基于栈的，如 Python, Ruby, .NET 的 CLR 等。&lt;/p&gt;

&lt;p&gt;基于寄存器的虚拟机，是为性能所生。引入寄存器假设固然关上了用于资源受限系统的门，却也打开了一扇通向进一步性能优化的窗。栈虚拟机的一大缺点就是要不停地将操作数在堆和栈之间来回拷贝。比方说一个简单的三个参数的函数调用，在传递参数上就需要至少三次入栈和出栈操作，而在寄存器上只要指定三个寄存器即可。现代处理器提供的通用寄存器支持，本身就是为了减少这类值的来回拷贝。尽管有 Hotspot 这样的技术能够将一段栈虚拟机指令转化为基于寄存器的机器指令，可毕竟没有直接从支持寄存器的中间语言翻译直接。前面说过，保持程序的结构是优化的先决条件。失去了“指定三个值”这样的结构的栈虚拟机，需要运行时间接的推断这个操作。而直接指定这些访问结构，将值直接映射到 CPU 的寄存器，正是这类虚拟机运行效率高的要点所在。Android 的 Dalvik, Perl 的 Parrot 都是基于寄存器的虚拟机，而 LLVM 则是基于寄存器假设的中间语言。其中，为了让 Android 程序更加快的运行，Google 不惜放弃 JVM 的指令集，而选择将 JVM 指令转化为基于有限个寄存器的 Dalvik 指令集。 Parrot 和 LLVM 则更加自由一些，假设了无穷多个寄存器。无论是有限还是无限个寄存器，省却不必要的值拷贝是这类中间语言的最大优点。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;JIT 和直接执行&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;JIT (Just-in-time) 是运行时的动态编译技术。不难看出，JIT 是针对中间语言的——将原语言的编译推迟到运行时并无意义，将中间语言的解释，部分转化为编译后的机器代码，则可以优化运行效率。JIT 之所以可行，一个基本假设是程序大多存在热点。D. E. Knuth 三十年前观察到的一个现象: 一段 FORTRAN 程序中不到 4% 的部分往往占用超过 50%的运行时间。因此，在运行时识别这样的热点并优化，可以事半功倍地提高执行效率。&lt;/p&gt;

&lt;p&gt;按照 Jython 作者 Jim Hugunin 的观测， JIT 技术出现后，同样功能的程序，运行于 Java 虚拟机上的字节码和直接编译成二进制代码的 C 程序几乎一样快，有的甚至比 C 快。乍一看虚拟机比原生代码快，理论上是不可能的。而实践中，因为 JIT 编译器可以识别运行时热点做出特别优化。相比之下，静态编译器的代码优化并不能完全推断出运行时热点。而且，有些优化技术，如将虚函数调用静态化，只有在运行时才能做到。在对热点深度优化的情况下，JIT 比直接生成的机器代码执行效率高并不是一件神奇的事情。引入了 JIT 的，以 Python 书写的 Python 执行器 pypy, 运行速度要比以 C 实现的 CPython 解释器快一到五倍，就是 JIT 技术魅力的一个明证。&lt;/p&gt;

&lt;p&gt;尽管 JIT 技术看上去很炫，实践中也能够做到几乎和原生二进制代码速度相近，我们必须承认，这只是一种补救相对慢的中间语言解释的一种措施罢了。设计语言平台时，设计者可能因为这样那样的原因而选择中间语言／虚拟机解决方案，或因为针对嵌入式系统(Java)，或因为跨平台要求(Android Dalvik)，或者仅仅因为设计者想偷懒不愿写一个从语言到CPU指令的编译器(Python/Ruby)。无论原因为何，当最初的原因已经不存在或不重要，而性能又成为重要考量的话，采用中间语言就显得舍近求远。JavaScript 引擎的进化就是一个生动的例子。&lt;/p&gt;

&lt;p&gt;JavaScript 语言最初只是一种协助 HTML 完成动态客户端内容的小语言。Netscape 浏览器中的JS 引擎，最初只是一个简单的解释器。自2004 年 Google 发布 Gmail 之后, Ajax 技术的发展对 JS 引擎的速度提出了更高的挑战。JavaScript 引擎的速度被当成一个浏览器是否领先于对手的关键指标。在此情况下，众多浏览器厂商纷纷卷入了一轮 JS 引擎速度的军备竞赛。&lt;/p&gt;

&lt;p&gt;最先挑起这场战争的是 Firefox, 目标是当时占据90%市场的 IE。Firefox 3 于2008年6月登场，其 JS 引擎 TraceMonkey 在栈虚拟机的基础上首次采用了 JIT 技术，在当时众多标准评测中超越了IE7。就在当月，WebKit 开发小组宣布了基于寄存器的 Squirrelfish 引擎，殊途同归，也是基于中间语言，尽管两者互相不兼容。&lt;/p&gt;

&lt;p&gt;到9月，Google 发布了第一个版本的 Chrome 浏览器以及新的 JS 引擎: V8。V8一反使用中间语言的设计套路，力求将 JS 直接编译到本地代码。Google 毫不掩饰 V8 在标准评测上比其他浏览器快的结果，因此造成了 Firefox 和Safari 开发者对各自 JS 引擎速度评测的一场恶战。到了9月的时候，Firefox 和 Safari 各自的引擎都比6月份的结果快到 20%到60% 不等。 而 V8 也赢得了许多眼球，催生了之后的 Node.js 项目。&lt;/p&gt;

&lt;p&gt;这场军备竞赛的一个结果，就是 V8 以外的引擎，也开始探索绕过中间语言从 JavaScript 直接生成二进制的可能性。SquirrelFish Extreme 就是自 Squirrelfish 衍生出来的一步本地代码的引擎。值得注意的是，尽管都是生成本地代码，V8 和 SquirrelFish Extreme 这样的编译器，并不是退回到传统的编译器技术上，因为他们已经吸收了许多对 JIT 编译器性能的研究成果。&lt;/p&gt;

&lt;p&gt;就在我写这篇文章的时候，Google 正在将 Android 执行环境，从原来的 Dalvik 虚拟机，换成可以直接生成机器代码的 ART 架构。ART 负责在 App 安装后一次将跨平台的字节码分发格式，编译成原生机器代码。20 多年前，为了跨平台，Java 采取了虚拟机的设计方案。如今，中间语言的跨平台的部分依然保留，但作为已经不直接参与执行了。硬件的进步带来的中间语言和虚拟机设计的进化，是当时的设计者如何也想不到的事情了。&lt;/p&gt;
</description>
				<pubDate>Sun, 11 May 2014 20:29:44 +0000</pubDate>
				<link>http://blog.youxu.info/2014/05/11/language-and-vm/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2014/05/11/language-and-vm/</guid>
			</item>
		
			<item>
				<title>现代人的必备知识：药理学</title>
				<description>&lt;p dir=&quot;ltr&quot;&gt;
  人们常说，是药三分毒。我们感性地知道药物是有毒性的，但轮到生病的时候，多数人还是会寻求药物治疗，而把“是药三分毒”放在了一边，或者“相信”药物的效用超过了毒性。这种相信，大多数时候并不是出于我们的理性的判断，而是依赖于医生的判断，以往的经验，或者药物本身的说明书。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  其实，作为一个现代人，我们完全有能力，也负有对自己和自己爱的人的责任，去了解药物的具体毒性，以理性地，正确地选择药物，从而走出感性地“是药三分毒”的认识，切实地了解药物的毒性。研究药物作用机理和毒性的知识的学科，叫做药理学（Pharmacology）。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  药理学关心的是药物的结构，作用机理，代谢方式，毒性等等的知识。这些知识看上去名词一大堆，牵涉到化学，分子生物等若干领域，其实只要掌握了一些基本的概念，一个受过高中教育的人完全可以理解。事实上，在美国，药理学是护士培训的必修课。护士并不比大多数读者具有更多的生物，化学或者科学知识。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  以一个很日常的例子说明一下药理学的作用。几乎所有人都用过的退烧药。常用的退烧药包含阿斯匹林 (&lt;a href=&quot;http://en.wikipedia.org/wiki/Aspirin&quot;&gt;Aspirin&lt;/a&gt;)，布洛芬 (&lt;a href=&quot;http://en.wikipedia.org/wiki/Ibuprofen&quot;&gt;Ibuprofen&lt;/a&gt;)，扑热息痛 (&lt;a href=&quot;http://en.wikipedia.org/wiki/Paracetamol&quot;&gt;Paracetamol&lt;/a&gt;，国内又叫百服宁，必理通或者泰诺) 三种。现在请听两道题题：1）这三种药一天一次还是一天多次，如果多次，间隔多长为好？2）如果你同时有胃溃疡，或者肝功能不好，该选择哪种药物？读者要说了，我又不是医生，我哪儿知道？其实，如果你有一些基本的药理学知识，回答以上问题轻而易举。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  药一天吃几次的问题，其实就是人体多长时间将药代谢掉的问题。在药理学里，我们用“半衰期(half life)”来衡量药物的代谢速度。如果你到英文维基百科上，分别输入 Asprin, Ibuprofen 和 Paracetamol，在右边的框里，很容易看到这三个药物的半衰期(300mg, 3.1-3.2小时，1.8-2小时和1-4小时)。人体对药物的代谢是非线性的，但从半衰期我们可以大致估计到在症状持续的情况下，这些药不可能在体内持续作用 24 小时。所以如果症状持续，我们可以一日多次服用。像扑热息痛，因为半衰期已经长达 4 小时，所以服药间隔最好要在 4 小时之上，这都是有药理学知识的人一眼看出的常识。再比如说，同样是抗生素，两颗阿红霉素(Azithromycin) 的半衰期长达68小时，而阿莫西林(Amoxicillin) 只有一个小时。所以你去药房拿药的时候，药剂师会给你几颗阿红霉素，或者一盒子阿莫西林。掌握药理学常识可以帮助我们理解这些药物之间的差别，并记得按时服药。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  药理学还研究一个药物的代谢途径，比如，是通过肝脏，肾脏还是其他，具体的代谢通道是什么。有了一些基本的药理学知识，我们就知道如果一个人肝功能有损伤，则要避免通过肝代谢的药物。家里养猫的人可能都知道，Paracetamol 对猫有剧毒，原因就是 Paracetamol 是肝代谢的，而猫的肝恰恰没有代谢 Paracetamol 所需要的酶。又比如说，阿司匹林 和布洛芬在药理学上都属于NSAID 药物。NSAID 药物的一大副作用是能够导致消化道溃疡，所以有消化道溃疡前史的患者最好谨慎服用。总之，虽然这些药都是属于“退烧药”，通过药理学，我们可以详细探究这些药的异同。如果我们知道了一个药的代谢渠道，在通过简单的基因测序如 23andme 知道我们自身有无相应的酶来代谢这些药物，在选择药物的时候，就不会像猫一样盲目地把 Paracetamol 往嘴里送，也不会因为无知而莫名其妙地把所爱的人推向危险的境地。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  言而总之，药理学知识可以帮助我们了解药物。现代药的说明书说白了是很严谨的药理学试验报告，而药理学知识就是读懂这个报告的钥匙。我相信药理学可以帮助我们更加科学和透明地选择和服用药物，让我们和我们所爱的人的生活更加美好。
&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;
  这个世界上有很多所谓的“传统医学”，而且信徒还不少。不管这些传统医学多么博大精深，多么神奇，如果这些传统医学给我或者我所爱的人开的药没有药理学支持，那么我们作为一个现代的，理性的人，唯一可做的，而且是最负责的，就是拒绝这些药物。把这些药物往嘴里送，就是接受了“是药三分毒”，而且还不知道是哪三分。
&lt;/p&gt;

&lt;p&gt;PS: Coursera 上有  &lt;a href=&quot;https://www.coursera.org/course/pharm101&quot;&gt;Fundamentals of Pharmacology&lt;/a&gt; 的公开课。我上过，受益无穷。&lt;/p&gt;

&lt;div&gt;
&lt;/div&gt;
</description>
				<pubDate>Wed, 29 May 2013 07:26:21 +0000</pubDate>
				<link>http://blog.youxu.info/2013/05/29/pharmacology/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2013/05/29/pharmacology/</guid>
			</item>
		
			<item>
				<title>编程珠玑番外篇之番外篇-N  答 UNIX 痛恨者王垠</title>
				<description>&lt;p&gt;(标题是标题党）&lt;/p&gt;

&lt;p&gt;王垠最近的&lt;a href=&quot;http://bbs.hupu.com/5187888.html&quot;&gt;一篇文章&lt;/a&gt;中，提出了很多有趣的观点。其中最核心的一点，就是 *NIX 系统的设计哲学非常糟糕，而 Windows 系统才是真正为开发者设计的系统。凡是涉及到哲学层面的争论，最后都是以谁也说服不了谁收场。我相信王垠有足够的理由来证明 UNIX 设计哲学的糟糕，但遗憾的是，他的文章并没有表现出这一点。我摘抄一些论点并作答复。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Unix 的 shell，命令，配置方式，图形界面，都是非常糟糕的。每一个新版本的 Ubuntu 都会在图形界面的设计上出现新的错误，让你感觉历史怎么会倒退。但是这只是表面现象。Linux 的图形界面（X window）在本质上几乎是不可治愈的恶疾。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;以现在的眼光看，X Windows 是一个设计过于繁复的系统。实际上，20年前出版的 The Unix Haters Handbook 里，就有&lt;a href=&quot;http://www.art.net/~hopkins/Don/unix-haters/x-windows/disaster.html&quot;&gt;专门的一章&lt;/a&gt;论述为什么 X Window 的 client-server 架构是糟糕的。可是，这和 Ubuntu 的设计演化之间似乎没有太多关联。Ubuntu 所谓的图形界面设计的错误（以 unity 为例），都是桌面环境层面的问题。一个设计师在这个层面犯错误，就像一个画家因为构图不够工整就去怪画布不行一样，之间还相差不少逻辑链条。&lt;/p&gt;

&lt;p&gt;X Window 和其他操作系统上的 GUI 系统最大的不同，是它和宿主操作系统的松耦合。因为这种松耦合的存在，在不需要图形界面的地方，操作系统可以不带 X Window。很多云服务的服务器，都是没有 X 的。当下如日中天的移动操作系统如 Android 和 iOS 都是 UNIX 家族操作系统，而这两者都没有用 X Window 提供 GUI 支撑，而是另外开发了一套专门适合触摸式移动设备的图形界面系统。图形系统和操作系统间的松耦合，使得操作系统可以从头搭建适合具体设备的图形界面交互(如 Cocoa Touch)，并且快速的迭代（如 Project Butter）。&lt;/p&gt;

&lt;p&gt;在 GUI 和内核的耦合关系上，架构的确决定了产品的形状。我们都知道，微软 NT 内核和 Widnows UI 系统是绑定在一起的。Windows Phone 8 要和 Windows 8 共享内核和其他组件的结果，就是它们都必须兼顾桌面和移动平台。为此，微软做出了两个可以做榔头也能做螺丝刀的东西。一个是 Windows 8，支持触摸屏，Modern UI 界面长得像手机界面；一个是 Windows Phone 8，界面很适合触摸设备，却又同时支持移植来的桌面程序，造成有的程序界面长得像桌面。无论你认为哪个操作系统的图形界面漂亮，哪条路更加有光明的未来，微软的这些系统之间的关系之繁复，开发迭代的周期如此之长，都是客观事实。&lt;/p&gt;

&lt;p&gt;UNIX 系统的Unix 的 shell，命令，配置方式的确有不少的问题，在痛恨者手册里也有详细的论述，&lt;a href=&quot;http://blog.youxu.info/2011/10/14/notes-on-the-unix-haters-handbook/&quot;&gt;我以前也写过&lt;/a&gt;，就不一一列举了。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Unix 依靠自己的“宗教”和“哲学”，“战胜”了别的系统在设计上的先进，统治了程序员的世界。胜者为王，可是 Unix 其实是一个暴君，它不允许你批评它的错误。它利用其它程序员的舆论压力，让每一个系统设计上的错误，都被说成是用户自己的失误。其它系统里面某些优秀的系统设计，也许就要被历史掩埋……&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;一个操作系统，是不可能凭着“宗教”和“哲学”就能统治程序员的世界的。程序员不是天主教徒，UNIX 也不是程序员世界的教皇。实际上，所谓的 UNIX 系统，不是一个特定的系统，而是一个家族的系统。这个家族的系统包罗万象。不喜欢微内核的做了宏内核，不喜欢一切还不都是文件的做了 Plan 9, 不喜欢 X Window 慢如蜗牛的做了 XGL 加速。优秀的设计不断地加入这个系统，改造这个系统。UNIX 来源于 Bell 实验室，X Window 却是 MIT 的，BSD 来自于 Berkeley, Solaris 来自于 SUN, Mac OS 来自于 Apple。如果说这里面有宗教的话，这一定是世界上最诡异的宗教，里面的教徒还天天打架。&lt;/p&gt;

&lt;p&gt;在 UNIX 系统中，所有的设计，都在开放的环境下竞争。我们可以说 UNIX 不是一个设计良好的系统，但是它的设计哲学在竞争中获胜的原因，不是因为它是“暴君”，控制了程序员的思想，而恰恰是因为它的开放，所以最终汇总了很多优秀的东西。至于 UNIX 这种不怎么好的系统为何最终获胜，&lt;a href=&quot;http://www.jwz.org/doc/worse-is-better.html&quot;&gt;20年前的一篇文章&lt;/a&gt;也讲得很清楚了。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;因为 TeX 的语言是非常糟糕的设计。它的设计者几乎完全不明白程序语言设计的基本原则，不明白什么叫做“抽象”。&lt;/p&gt;

  &lt;p&gt;而这些源于 Unix 的工具却像是“魔鬼棋”或者“三国杀”，有太多的，无聊的，人造的规则。有些人鄙视图形界面，鄙视 IDE，鄙视含有垃圾回收的语言（比如 Java），鄙视一切“容易”的东西。他们却不知道，把自己沉浸在别人设计的繁复的规则中，是始终无法成为大师的。就像一个人，他有能力学会各种“魔鬼棋”的规则，却始终无法达到象棋大师的高度。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里，王垠把两个不相关的东西放到了一起。一个是工具的设计哲学，一个是我们如何学习知识。魔鬼棋本身是一种工具设计哲学，和成为大师无关。&lt;/p&gt;

&lt;p&gt;在&lt;a href=&quot;http://blog.youxu.info/2012/02/02/software-tools-1/&quot;&gt;军刀工具&lt;/a&gt;一文中我提过，面向特定领域的软件工具之所以让人觉得复杂，是因为这个问题本身复杂。我们把解决特定领域问题而所需的知识叫做”领域模型“(domain model)。如果我们不了解领域模型，就不能理解为什么 Photoshop 比系统自带的 Paint 复杂几千倍, 或者为什么我们需要正则表达式这种诡异的东西。我们讲的复杂与简单，都是工具设计哲学层面的。&lt;/p&gt;

&lt;p&gt;以王垠说的 TeX 为例。写出《计算机程序设计艺术》的 Knuth 到底知不知道程序语言设计的基本原则我们可以不加讨论。了解一点字体设计和排版的都知道，计算机排版问题是个复杂的问题。的确，软件工具的设计目标，是把复杂的问题简化。然而，大多数人不知道的是，简化问题是一个两步过程。第一步，我们需要把现实的问题映射到一个领域模型。第二步，是把这个模型简化到我们人可以处理的地步。很多时候这两步合并起来了，让我们觉得这两步好像是一步，并且认为所有的设计，都应该朝简化的方向走。这是一个对设计的错误认识。&lt;/p&gt;

&lt;p&gt;举个非计算机领域的例子：用电饭锅煮饭非常简单，加米加水再按个按钮就行了。电饭锅的设计者的设计目标是操作简单且能完美地煮米。作为工具的设计者，它一方面需要了解大米是怎么煮熟的，另一方面需要提供给用户一个简单的按钮。TeX 作者，从一开始就不是设计一个电饭锅，而是一个精确的温控炉子。有了这个精确的温控炉子，想烧饭的可以把它封装成电饭锅，想做蛋糕的可以把它封装成蛋糕烤箱。设计电饭锅的人的设计，并不比设计精确的温控炉子的人好，或者差。设计者的初衷决定了产品的形状。 Kunth 的初衷，正是设计一个可以让他人排版出任何想排版的东西的系统。也就是说，做出一个最终非常简单的，只有一个按钮的排版系统不是他的设计目标。做出一个可以高度定制的系统才是他的目标。&lt;/p&gt;

&lt;p&gt;其实，TeX 本身也是一个由繁到简的软件系统。它把所有排版中的问题，都提炼成了一些控制原语。有了这些控制原语，针对特定领域做优化就不是问题了。现在通用的科学出版排版工具 LaTeX, 正是这样的一种优化。这是有心设计的结果。我们抱怨 TeX 复杂，其实是抱怨排版本身复杂。Windows 系统上有许多排版软件，可以毫不客气地说，没有一个可以达到 TeX 所能到达的精确控制。以此责怪 UNIX 下的软件工具是魔鬼棋，就类似于责怪 Photoshop 为啥不象 Paint 那样简单一样，有选择性地忽视了两者所要解决地问题不一样。&lt;/p&gt;

&lt;p&gt;我欢迎所有的 UNIX 使用者加入痛恨者阵营，因为我也是 UNIX 痛恨者。只有成为了 UNIX 痛恨者，你才是一个真正的 UNIX 使用者。至于 Windows, 我们对它没有感情，无所谓爱恨。&lt;/p&gt;
</description>
				<pubDate>Sun, 03 Mar 2013 10:07:37 +0000</pubDate>
				<link>http://blog.youxu.info/2013/03/03/unix-haters-2/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2013/03/03/unix-haters-2/</guid>
			</item>
		
			<item>
				<title>佛教艺术中的沙</title>
				<description>&lt;ul&gt;
  &lt;li&gt;“沙”　是佛教里很值得一提的物件，很多佛教艺术都和沙有关。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;日本禅宗的“枯山水”就是一种依赖于沙的园林艺术。枯山水在西方很有名，以至于在西方直接被称为禅花园(Zen Garden)。一般的园林都会通过假山和水构景，通过人造的山和水，来引起观者自然的联想，从而联系人与自然。而枯山水园林却反其道而行，不采用真正的山，也不摆放真实的树，竹等物。枯山水中的水，是细细耙制的静态的白色砂石，模拟水的动态形态；枯山水中的植物也极少或者没有。这种美学上的差异，其实是和中日两国禅宗在修行上的侧重不同有关的。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.youxu.info/wp-content/uploads/2012/10/360px-Daisen-in2.jpeg&quot;&gt;&lt;img class=&quot;alignleft size-medium wp-image-1268&quot; src=&quot;http://blog.youxu.info/wp-content/uploads/2012/10/360px-Daisen-in2-225x300.jpg&quot; alt=&quot;&quot; width=&quot;225&quot; height=&quot;300&quot; srcset=&quot;http://blog.youxu.info/wp-content/uploads/2012/10/360px-Daisen-in2-225x300.jpg 225w, http://blog.youxu.info/wp-content/uploads/2012/10/360px-Daisen-in2.jpeg 360w&quot; sizes=&quot;(max-width: 225px) 100vw, 225px&quot; /&gt;&lt;/a&gt;中国禅宗传统上就是位于名山大川，因此在修行时秉承了一种自然主义的路线，让修行者在见山是山，见水是水的自然景观或者园林中修行。日本的禅宗主要继承了曹洞和临济两家。曹洞侧重于打坐和冥想，即“只管打坐”（&lt;em&gt;Shikantaza&lt;/em&gt;)。临济强调”心即是佛”，也是促使人向内求索。在这种思想指导下，园林就不再坚持自然主义，而转为为修行着提供安心之法。枯山水正是这种哲学的体现。一个枯山水园林一旦建成，一年四季景色完全相同，恒久不变，宁静无碍。在枯山水中修行，心不会四处乱走。&lt;/p&gt;

&lt;p&gt;枯山水是用静态景观来展现这个大千世界动态的一瞬间，而藏传佛教里的坛城沙画 (&lt;em&gt;Sand Mandala)&lt;/em&gt;，则是用动态的构建，来展现万事无常这个恒久不变的佛理。构建坛城沙画的目的，不是为了让它成为一项艺术品，而是为了最后摧毁它。这种最终什么也得不到的艺术创作，正是说明了佛教里一切无常的道理。&lt;/p&gt;

&lt;p&gt;佛教的艺术家很早就意识到沙是彩色的。《大方广佛华严经》就提到过四条不同的大河流出不同颜色的细砂：“恒伽河口流出银沙，私陀河口流出金刚沙，信度河口流出金沙，缚刍河口流出琉璃沙”。结合华严经所说的恒河沙中的世界，用彩色的沙构建大千世界这种佛教艺术的出现是自然的。&lt;/p&gt;

&lt;p&gt;为了构建坛城沙画，喇嘛们需要用尺子和圆规仔细的规划沙画的基本结构和几何形态。同时，所有的彩色沙都是仔细遴选甚至磨制而成。这些彩色的细沙被装入一个小口沙漏，然后由有经验的喇嘛，将这些细沙细细铺出。构建沙画是费时费力的，往往需要众多喇嘛们连续好天的工作。而不管花多少力气，多么美丽的沙画，只要沙盘倾覆，都一瞬间化为无形。从这个意义上来说，要揭示世事无常的道理，没有沙更加贴切的道具了。&lt;/p&gt;

&lt;div id=&quot;attachment_1269&quot; style=&quot;width: 310px&quot; class=&quot;wp-caption alignright&quot;&gt;
  &lt;a href=&quot;http://blog.youxu.info/wp-content/uploads/2012/10/320px-Amazing_sand_mandala.jpeg&quot;&gt;&lt;img class=&quot;size-medium wp-image-1269&quot; src=&quot;http://blog.youxu.info/wp-content/uploads/2012/10/320px-Amazing_sand_mandala-300x225.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;225&quot; srcset=&quot;http://blog.youxu.info/wp-content/uploads/2012/10/320px-Amazing_sand_mandala-300x225.jpg 300w, http://blog.youxu.info/wp-content/uploads/2012/10/320px-Amazing_sand_mandala.jpeg 320w&quot; sizes=&quot;(max-width: 300px) 100vw, 300px&quot; /&gt;&lt;/a&gt;
  
  &lt;p class=&quot;wp-caption-text&quot;&gt;
    坛城沙画
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;坛城沙画一旦建立，它的唯一命运就是被摧毁。高级别的喇嘛会先诵经一段，然后以一定的规则将沙画摧毁，将各色细沙汇作一堆，装入瓶中，撒入江河。就像熵只能增加一样，美丽的沙画的每一次破坏都是不可逆的。这种摧毁美丽艺术品的悲剧感和无力感，正是佛教想要说明的道理：诸行无常，是生灭法，生灭灭已，寂灭为乐。&lt;/p&gt;

&lt;p&gt;佛经里对沙的数量，沙的色彩和沙的无常感都有论述。有趣的是，尽管大多数人认为“一花一世界，一沙一凡尘”出自于佛经，实际上佛经中从来没有明确的提出过这个论题。这个很有佛学意味的句子，实际上来自于英国诗人_William Blake_ 的《纯真预言》：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;div&gt;
  To see a world in a grain of sand,&lt;br /&gt; And a heaven in a wild flower,&lt;br /&gt; Hold infinity in the palm of your hand,&lt;br /&gt; And eternity in an hour.&amp;lt;/p&amp;gt; 
  
  &lt;div&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
</description>
				<pubDate>Wed, 24 Oct 2012 22:07:35 +0000</pubDate>
				<link>http://blog.youxu.info/2012/10/24/sands-in-buddhism/</link>
				<guid isPermaLink="true">http://blog.youxu.info/2012/10/24/sands-in-buddhism/</guid>
			</item>
		
	</channel>
</rss>
